Casal2
Call: ..\..\..\..\..\BuildSystem\bin\windows\release_cppad\casal2 -e -o params_est.out
Date: Tue Jul 21 05:43:09 2020
Version: 2020-07-20 04:47:36 UTC (rev. da3dd0c3)
Copyright (c) 2020 - 2020, NIWA (www.niwa.co.nz)
Environment: machine:niwa-computer, user:niwauser, os:Windows_NT, pid:20276

[WARNING] C:\workspace\casal2-windows-rlibrary\CASAL2\source\Estimates\Manager.cpp(line: 95): Estimates were removed because of matching lower and upper bounds. Originally had 127 estimates, now have 42
This is Ipopt version 3.11.9, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Starting derivative checker for first derivatives.


No errors detected by derivative checker.

Number of nonzeros in equality constraint Jacobian...:        0
Number of nonzeros in inequality constraint Jacobian.:       42
Number of nonzeros in Lagrangian Hessian.............:      903

Total number of variables............................:       42
                     variables with only lower bounds:        0
                variables with lower and upper bounds:       42
                     variables with only upper bounds:        0
Total number of equality constraints.................:        0
Total number of inequality constraints...............:        1
        inequality constraints with only lower bounds:        1
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  4.0691148e+02 0.00e+00 9.18e+01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0 y
   1  3.3511257e+02 0.00e+00 2.63e+01  -1.0 2.46e-01   2.0 8.85e-01 9.90e-01f  1 Nhj
   2  2.6880282e+02 0.00e+00 1.09e+01  -1.0 4.15e-01   1.5 9.90e-01 9.90e-01f  1
   3  2.5269761e+02 0.00e+00 9.63e+02  -1.0 5.09e-01   1.0 9.90e-01 1.00e+00f  1
   4  2.4584951e+02 0.00e+00 4.03e+00  -1.0 1.21e+00   0.6 1.00e+00 1.00e+00f  1
   5  2.4049473e+02 0.00e+00 1.90e+06  -3.8 1.70e+00   0.1 8.10e-01 1.00e+00f  1
   6  2.3885988e+02 0.00e+00 4.68e+05  -3.8 2.75e+03    -  7.54e-01 2.50e-01f  3
   7  2.3838365e+02 0.00e+00 1.24e+03  -3.8 1.24e+02    -  9.97e-01 1.00e+00f  1
   8  2.3837143e+02 0.00e+00 8.15e-02  -3.8 9.87e+00    -  1.00e+00 1.00e+00f  1
   9  2.3837049e+02 0.00e+00 3.97e-02  -3.8 1.80e-01    -  1.00e+00 1.00e+00f  1
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
  10  2.3837030e+02 0.00e+00 1.38e-02  -3.8 9.19e-02    -  1.00e+00 1.00e+00f  1
  11  2.3837026e+02 0.00e+00 2.64e-03  -3.8 2.30e-02    -  1.00e+00 1.00e+00f  1
  12  2.3837024e+02 0.00e+00 6.42e-04  -5.7 2.57e-02    -  1.00e+00 1.00e+00f  1
  13  2.3837023e+02 0.00e+00 1.37e-04  -5.7 2.16e-02    -  1.00e+00 1.00e+00f  1
  14  2.3837023e+02 0.00e+00 4.92e-05  -5.7 1.67e-02    -  1.00e+00 1.00e+00f  1
  15  2.3837023e+02 0.00e+00 2.08e-05  -5.7 1.10e-02    -  1.00e+00 1.00e+00f  1
  16  2.3837023e+02 0.00e+00 3.55e-06  -5.7 8.93e-02    -  1.00e+00 7.81e-03f  8
  17  2.3837023e+02 0.00e+00 1.73e+02  -8.6 7.92e-03    -  1.00e+00 6.25e-02f  5
  18  2.3837023e+02 0.00e+00 1.73e+02  -8.6 1.97e+00    -  1.00e+00 3.05e-05f 16
  19  2.3837023e+02 0.00e+00 1.73e+02  -8.6 2.64e+00    -  1.00e+00 7.63e-06f 18
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
  20  2.3837023e+02 0.00e+00 1.73e+02  -8.6 2.35e+00    -  1.00e+00 9.54e-07f 21

Number of Iterations....: 20

                                   (scaled)                 (unscaled)
Objective...............:   2.3837022675921881e+02    2.3837022675921881e+02
Dual infeasibility......:   1.7271904875913481e+02    1.7271904875913481e+02
Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
Complementarity.........:   5.0182649095489274e-09    5.0182649095489274e-09
Overall NLP error.......:   1.7271904875913481e+02    1.7271904875913481e+02


Number of objective function evaluations             = 110
Number of objective gradient evaluations             = 21
Number of equality constraint evaluations            = 0
Number of inequality constraint evaluations          = 110
Number of equality constraint Jacobian evaluations   = 0
Number of inequality constraint Jacobian evaluations = 21
Number of Lagrangian Hessian evaluations             = 20
Total CPU secs in IPOPT (w/o function evaluations)   =     37.669
Total CPU secs in NLP function evaluations           =    580.501

EXIT: Maximum Number of Iterations Exceeded.
*initialisation_partition[Init]
values {d}
category 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
male 166940.053555 145130.710376 126170.578274 109687.431288 95357.671710 82899.977209 72069.777901 62654.454942 54469.166388 47353.218375 41166.910367 35788.792553 31113.281541 27048.587538 23514.912332 20442.882691 17772.188422 118265.383304
female 157218.221673 128719.393028 105386.525589 86283.189460 70642.700684 57837.351531 47353.218375 38769.536141 31741.811521 25987.997251 21277.172560 17420.275513 14262.515290 11677.159884 9560.449906 7827.434351 6408.561221 28945.263709
*end

*partition[state1]
year: 2001
time_step: 1
values {d_r}
category 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
male 163966.613186 134869.765766 138561.631364 151881.833500 75632.625705 42979.317890 30407.006222 25876.963835 27536.226548 16913.819779 7795.585591 3756.227108 1910.989994 1098.654123 724.286370 527.298502 408.101864 4903.205836
female 154511.931932 123440.894486 130442.911367 148276.745912 75115.973479 42603.668489 29971.938146 25384.226109 26764.425328 16061.363997 7018.799588 3122.556936 1448.934964 744.329273 433.222001 280.528170 195.335679 1378.244745
*end

*partition[state1]
year: 2010
time_step: 1
values {d_r}
category 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
male 140706.396284 151921.201381 50283.240294 88241.959947 74485.679170 22519.236535 25575.509945 19796.865786 11303.075946 10781.498325 7716.113680 7351.923779 7827.555576 3863.559848 2192.814640 1551.025180 1319.859651 3344.477879
female 132610.227568 139518.017465 48191.397083 89804.968125 78345.832646 23657.719708 26130.781210 19159.724335 10161.503848 9023.162204 6098.423206 5520.168702 5557.889875 2593.354032 1396.237996 950.748396 788.484214 1746.591874
*end

*partition[state1]
year: 2019
time_step: 1
values {d_r}
category 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
male 143496.854268 120716.004791 55875.332631 53664.397229 51403.879936 34814.283082 46801.541152 11099.694697 15513.633428 9391.876116 8526.496467 2571.427478 4354.800489 3636.844328 1097.841716 1246.471802 964.744323 2789.787122
female 135245.902087 110425.416745 52382.110005 52124.132936 51185.223704 34748.222019 45895.497091 10625.056694 14372.099946 8342.269641 7235.490012 2081.966040 3360.046829 2659.627533 755.206668 802.401332 573.626805 1270.088814
*end

*estimate_value[estimated_values]
values {d}
process[Recruitment].b0 age_length[asMm0].linf age_length[asMm0].cv_last selectivity[potSurveySel_male].a50 selectivity[potSurveySel_male].ato95 selectivity[potSurveySel_female].a50 selectivity[potSurveySel_female].ato95 process[Recruitment].ycs_values{1980} process[Recruitment].ycs_values{1981} process[Recruitment].ycs_values{1982} process[Recruitment].ycs_values{1983} process[Recruitment].ycs_values{1984} process[Recruitment].ycs_values{1985} process[Recruitment].ycs_values{1986} process[Recruitment].ycs_values{1987} process[Recruitment].ycs_values{1988} process[Recruitment].ycs_values{1989} process[Recruitment].ycs_values{1990} process[Recruitment].ycs_values{1991} process[Recruitment].ycs_values{1992} process[Recruitment].ycs_values{1993} process[Recruitment].ycs_values{1994} process[Recruitment].ycs_values{1995} process[Recruitment].ycs_values{1996} process[Recruitment].ycs_values{1997} process[Recruitment].ycs_values{1998} process[Recruitment].ycs_values{1999} process[Recruitment].ycs_values{2000} process[Recruitment].ycs_values{2001} process[Recruitment].ycs_values{2002} process[Recruitment].ycs_values{2003} process[Recruitment].ycs_values{2004} process[Recruitment].ycs_values{2005} process[Recruitment].ycs_values{2006} process[Recruitment].ycs_values{2007} process[Recruitment].ycs_values{2008} process[Recruitment].ycs_values{2009} process[Recruitment].ycs_values{2010} process[Recruitment].ycs_values{2011} process[Recruitment].ycs_values{2012} process[Recruitment].ycs_values{2013} process[Recruitment].ycs_values{2014}
14199.6 47.3306 0.0597765 3.03962 0.192075 3.3145 1.03325 0.235225 0.232175 0.233214 0.24199 0.264644 0.314841 0.416172 0.601743 0.902116 1.37833 1.56001 1.02891 0.847878 0.846852 1.06536 1.54897 1.05327 0.803063 0.816688 0.628379 0.802062 0.745814 0.467129 1.09423 0.921275 0.384129 0.905891 0.709813 0.835569 0.426295 1.28746 0.690332 0.736378 0.561556 0.439783
std_dev {d}
process[Recruitment].b0 age_length[asMm0].linf age_length[asMm0].cv_last selectivity[potSurveySel_male].a50 selectivity[potSurveySel_male].ato95 selectivity[potSurveySel_female].a50 selectivity[potSurveySel_female].ato95 process[Recruitment].ycs_values{1980} process[Recruitment].ycs_values{1981} process[Recruitment].ycs_values{1982} process[Recruitment].ycs_values{1983} process[Recruitment].ycs_values{1984} process[Recruitment].ycs_values{1985} process[Recruitment].ycs_values{1986} process[Recruitment].ycs_values{1987} process[Recruitment].ycs_values{1988} process[Recruitment].ycs_values{1989} process[Recruitment].ycs_values{1990} process[Recruitment].ycs_values{1991} process[Recruitment].ycs_values{1992} process[Recruitment].ycs_values{1993} process[Recruitment].ycs_values{1994} process[Recruitment].ycs_values{1995} process[Recruitment].ycs_values{1996} process[Recruitment].ycs_values{1997} process[Recruitment].ycs_values{1998} process[Recruitment].ycs_values{1999} process[Recruitment].ycs_values{2000} process[Recruitment].ycs_values{2001} process[Recruitment].ycs_values{2002} process[Recruitment].ycs_values{2003} process[Recruitment].ycs_values{2004} process[Recruitment].ycs_values{2005} process[Recruitment].ycs_values{2006} process[Recruitment].ycs_values{2007} process[Recruitment].ycs_values{2008} process[Recruitment].ycs_values{2009} process[Recruitment].ycs_values{2010} process[Recruitment].ycs_values{2011} process[Recruitment].ycs_values{2012} process[Recruitment].ycs_values{2013} process[Recruitment].ycs_values{2014}
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
*end

*objective_function[obj_fun]
values {v}
observation->potSurvey-2010 -1.03819
observation->potSurvey-2014 -1.01953
observation->potSurvey-2018 -1.19591
observation->potCPUE-1990 -0.161596
observation->potCPUE-1991 1.09772
observation->potCPUE-1992 -1.05674
observation->potCPUE-1993 -1.99117
observation->potCPUE-1994 -2.14353
observation->potCPUE-1995 -2.08534
observation->potCPUE-1996 -2.18631
observation->potCPUE-1997 -1.95996
observation->potCPUE-1998 -2.15712
observation->potCPUE-1999 -1.68919
observation->potCPUE-2000 -2.19164
observation->potCPUE-2001 -2.16426
observation->potCPUE-2002 -2.04219
observation->potCPUE-2003 -2.17241
observation->potCPUE-2004 -2.19215
observation->potCPUE-2005 -1.90843
observation->potCPUE-2006 -1.79259
observation->potCPUE-2007 -2.17583
observation->potCPUE-2008 -2.18815
observation->potCPUE-2009 -2.05115
observation->potCPUE-2010 -2.1223
observation->potCPUE-2011 -1.87455
observation->potCPUE-2012 -1.76652
observation->potCPUE-2013 -1.77539
observation->potCPUE-2014 -1.03756
observation->potCPUE-2015 -1.85141
observation->potCPUE-2016 -2.09163
observation->potCPUE-2017 -2.10391
observation->potCPUE-2018 -1.35197
observation->AFpotSurvey-2010 39.6594
observation->AFpotSurvey-2014 39.3707
observation->AFpotSurvey-2018 39.1652
observation->AFpotFishing-2018 47.1034
observation->AFpotFishing-2019 7.88812
observation->lgobookLF 54.894
observation->rec.catch.LF 67.7273
prior->B0->process[Recruitment].b0 9.56097
prior->male_Linf->age_length[asMm0].linf 0
prior->male_cv2->age_length[asMm0].cv_last 0
prior->potSurvey_mA50->selectivity[potSurveySel_male].a50 0
prior->potSurvey_mAto95->selectivity[potSurveySel_male].ato95 0
prior->potSurvey_fA50->selectivity[potSurveySel_female].a50 0
prior->potSurvey_fAto95->selectivity[potSurveySel_female].ato95 0
prior->YCS->process[Recruitment].ycs_values{1980} 1.27335
prior->YCS->process[Recruitment].ycs_values{1981} 1.31548
prior->YCS->process[Recruitment].ycs_values{1982} 1.301
prior->YCS->process[Recruitment].ycs_values{1983} 1.18375
prior->YCS->process[Recruitment].ycs_values{1984} 0.918064
prior->YCS->process[Recruitment].ycs_values{1985} 0.476744
prior->YCS->process[Recruitment].ycs_values{1986} -0.0268512
prior->YCS->process[Recruitment].ycs_values{1987} -0.303939
prior->YCS->process[Recruitment].ycs_values{1988} -0.0988267
prior->YCS->process[Recruitment].ycs_values{1989} 0.687174
prior->YCS->process[Recruitment].ycs_values{1990} 1.02705
prior->YCS->process[Recruitment].ycs_values{1991} 0.0825015
prior->YCS->process[Recruitment].ycs_values{1992} -0.164812
prior->YCS->process[Recruitment].ycs_values{1993} -0.165976
prior->YCS->process[Recruitment].ycs_values{1994} 0.13993
prior->YCS->process[Recruitment].ycs_values{1995} 1.0062
prior->YCS->process[Recruitment].ycs_values{1996} 0.120661
prior->YCS->process[Recruitment].ycs_values{1997} -0.212329
prior->YCS->process[Recruitment].ycs_values{1998} -0.198632
prior->YCS->process[Recruitment].ycs_values{1999} -0.307466
prior->YCS->process[Recruitment].ycs_values{2000} -0.213308
prior->YCS->process[Recruitment].ycs_values{2001} -0.261618
prior->YCS->process[Recruitment].ycs_values{2002} -0.161211
prior->YCS->process[Recruitment].ycs_values{2003} 0.1867
prior->YCS->process[Recruitment].ycs_values{2004} -0.0736262
prior->YCS->process[Recruitment].ycs_values{2005} 0.0918333
prior->YCS->process[Recruitment].ycs_values{2006} -0.0939337
prior->YCS->process[Recruitment].ycs_values{2007} -0.284661
prior->YCS->process[Recruitment].ycs_values{2008} -0.178552
prior->YCS->process[Recruitment].ycs_values{2009} -0.0583793
prior->YCS->process[Recruitment].ycs_values{2010} 0.521264
prior->YCS->process[Recruitment].ycs_values{2011} -0.294124
prior->YCS->process[Recruitment].ycs_values{2012} -0.268309
prior->YCS->process[Recruitment].ycs_values{2013} -0.285673
prior->YCS->process[Recruitment].ycs_values{2014} -0.0964534
additional_prior->PrSurveyQ -11.3671
additional_prior->PrCPUEQ -8.33281
additional_prior->YCS_average_1 0.55906
total_score 238.37
*end

*derived_quantity[DerivedQuantities]
SSB {L}
type: biomass
initialisation_phase[1]: 14199.6
values {v}
1900 14199.6
1901 14165.2
1902 14116.1
1903 14055.5
1904 13984.9
1905 13905.3
1906 13817.7
1907 13722.8
1908 13621.6
1909 13514.6
1910 13402.4
1911 13285.7
1912 13165.3
1913 13041.5
1914 12914.7
1915 12785.1
1916 12653
1917 12518.4
1918 12381.9
1919 12243.3
1920 12102.8
1921 11960.3
1922 11816.1
1923 11670
1924 11522.2
1925 11372.7
1926 11221.5
1927 11069
1928 10914.8
1929 10759.3
1930 10602.2
1931 10443.7
1932 10284.6
1933 10096.5
1934 9775.08
1935 9887.81
1936 10143
1937 10375.9
1938 10634.2
1939 10857.1
1940 11110.4
1941 11305.2
1942 11472.5
1943 11584.6
1944 11486.5
1945 11325.1
1946 11120.4
1947 10777.6
1948 10498.2
1949 10185.3
1950 9851.75
1951 9617.77
1952 9386.18
1953 9438.59
1954 9524.13
1955 9594.71
1956 9517.32
1957 9478.56
1958 9468.21
1959 9493.61
1960 9375.8
1961 9344.34
1962 9273.25
1963 9221.59
1964 9275.12
1965 9431.13
1966 9557.38
1967 9581.9
1968 9614.46
1969 9722.41
1970 9779.14
1971 9856.43
1972 10042.8
1973 10013.1
1974 10005.3
1975 10151.8
1976 10289.8
1977 10448.2
1978 10600.3
1979 10773
1980 10798
1981 10756.9
1982 10790.8
1983 10599.2
1984 10164.1
1985 9434.98
1986 8624.05
1987 7792.58
1988 6933.96
1989 6240.18
1990 5558.94
1991 4902.98
1992 4720.97
1993 4845.94
1994 5148.58
1995 5480.32
1996 5634.15
1997 5673.08
1998 5894.99
1999 6168.74
2000 6551.86
2001 6653.19
2002 6577.91
2003 6485.19
2004 6397.06
2005 6113.57
2006 5738.05
2007 5506.72
2008 5320.61
2009 5140.03
2010 4948.31
2011 4824.08
2012 4739.83
2013 4682.31
2014 4648.44
2015 4773.6
2016 4816
2017 4682.6
2018 4613.41
2019 4465.24
end {L}
*end

*process[Recruitment]
age: 3
b0: 14199.6
b0_initialisation_phase:
categories: male female
label: Recruitment
proportions: 0.5 0.5
r0: 384054
ssb: SSB
ssb_offset: 3
standardise_ycs_years: 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014
steepness: 0.75
type: recruitment_beverton_holt
ycs_years: 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016
standardised_ycs: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0.316314 0.312212 0.31361 0.32541 0.355874 0.423375 0.559639 0.809181 1.2131 1.85348 2.0978 1.3836 1.14017 1.13879 1.43263 2.08295 1.41636 1.0799 1.09822 0.844999 1.07855 1.00292 0.628161 1.47144 1.23886 0.51655 1.21818 0.954506 1.12361 0.57325 1.73129 0.928309 0.990228 0.75514 0.591389 1 1
ycs_values: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0.235225 0.232175 0.233214 0.24199 0.264644 0.314841 0.416172 0.601743 0.902116 1.37833 1.56001 1.02891 0.847878 0.846852 1.06536 1.54897 1.05327 0.803063 0.816688 0.628379 0.802062 0.745814 0.467129 1.09423 0.921275 0.384129 0.905891 0.709813 0.835569 0.426295 1.28746 0.690332 0.736378 0.561556 0.439783 1 1
true_ycs: 1 1 1 1 0.999798 0.999507 0.999146 0.998722 0.998239 0.997702 0.997113 0.996476 0.995794 0.995068 0.9943 0.993495 0.992654 0.991777 0.990864 0.989916 0.988932 0.987914 0.986859 0.985768 0.984638 0.983468 0.982257 0.981003 0.979706 0.978363 0.976973 0.975534 0.974045 0.972502 0.970902 0.969253 0.967244 0.963651 0.964935 0.967746 0.970205 0.972819 0.974987 0.977354 0.97911 0.980575 0.981536 0.980697 0.979287 0.977445 0.974223 0.971457 0.9682 0.964527 0.961816 0.959016 0.95966 0.960698 0.961543 0.960616 0.960147 0.960022 0.96033 0.958888 0.958497 0.957606 0.956951 0.95763 0.959569 0.961098 0.96139 0.961777 0.963043 0.963698 0.96458 0.966658 0.966331 0.966245 0.967841 0.969307 0.970948 0.972482 0.974178 0.308223 0.304102 0.305566 0.316452 0.344476 0.406278 0.531029 0.757294 1.11568 1.6754 1.85723 1.19481 0.976742 0.980992 1.24957 1.83911 1.2571 0.9597 0.982841 0.762298 0.982942 0.916307 0.572849 1.33874 1.12456 0.465268 1.08486 0.843538 0.986433 0.499835 1.49791 0.798918 0.849021 0.645758 0.504931 0.8587 0.860312
Recruits: 384054 384054 384054 384054 383976 383864 383726 383563 383377 383171 382945 382700 382438 382159 381864 381555 381232 380895 380545 380181 379803 379412 379007 378588 378154 377704 377239 376758 376259 375744 375210 374657 374085 373493 372879 372245 371473 370094 370587 371666 372611 373615 374447 375356 376031 376593 376962 376640 376099 375391 374154 373092 371841 370430 369389 368314 368561 368960 369284 368928 368748 368700 368818 368264 368114 367772 367520 367781 368526 369113 369225 369374 369860 370112 370450 371248 371123 371090 371703 372266 372896 373485 374136 118374 116791 117354 121535 132297 156032 203944 290841 428481 643444 713274 458870 375121 376754 479901 706317 482792 368576 377464 292763 377502 351911 220005 514146 431892 178688 416645 323964 378843 191963 575279 306827 326070 248006 193921 329787 330406
SSB: 14199.6 14199.6 14199.6 14199.6 14165.2 14116.1 14055.5 13984.9 13905.3 13817.7 13722.8 13621.6 13514.6 13402.4 13285.7 13165.3 13041.5 12914.7 12785.1 12653 12518.4 12381.9 12243.3 12102.8 11960.3 11816.1 11670 11522.2 11372.7 11221.5 11069 10914.8 10759.3 10602.2 10443.7 10284.6 10096.5 9775.08 9887.81 10143 10375.9 10634.2 10857.1 11110.4 11305.2 11472.5 11584.6 11486.5 11325.1 11120.4 10777.6 10498.2 10185.3 9851.75 9617.77 9386.18 9438.59 9524.13 9594.71 9517.32 9478.56 9468.21 9493.61 9375.8 9344.34 9273.25 9221.59 9275.12 9431.13 9557.38 9581.9 9614.46 9722.41 9779.14 9856.43 10042.8 10013.1 10005.3 10151.8 10289.8 10448.2 10600.3 10773 10798 10756.9 10790.8 10599.2 10164.1 9434.98 8624.05 7792.58 6933.96 6240.18 5558.94 4902.98 4720.97 4845.94 5148.58 5480.32 5634.15 5673.08 5894.99 6168.74 6551.86 6653.19 6577.91 6485.19 6397.06 6113.57 5738.05 5506.72 5320.61 5140.03 4948.31 4824.08 4739.83 4682.31 4648.44 4773.6 4816
*end

*process[Mortality]
categories: male female
label: Fishing
m: 0.14 0.2
selectivities: One One
time_step_ratio: 1
type: mortality_instantaneous_retained
year: 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019
fishing_pressure[FishingLine]: 0 0.00104498 0.00209577 0.00315539 0.00421854 0.00529556 0.00638045 0.00749124 0.00860544 0.009749 0.0109072 0.0120898 0.0132982 0.0145247 0.0157795 0.017055 0.0183701 0.0197089 0.0210726 0.0224715 0.0239075 0.0253823 0.0268889 0.0284386 0.0300337 0.0316669 0.0333501 0.035076 0.0368674 0.0387074 0.0405983 0.0425544 0.0444373 0.0495607 0.0666789 0.018086 0.00724536 0.0102265 0.00561334 0.00787564 0.0023686 0.00691999 0.00734827 0.0111203 0.0302539 0.0346531 0.0396225 0.0552707 0.0506544 0.0584661 0.0643737 0.0571256 0.061579 0.0302518 0.0304556 0.032142 0.0490027 0.0428434 0.0402492 0.0363236 0.0538284 0.0424233 0.0489148 0.0466471 0.034516 0.0229508 0.0267296 0.0372087 0.0343015 0.0249218 0.0309653 0.0271451 0.0139846 0.0386169 0.0331408 0.015717 0.0175847 0.0140321 0.0137376 0.0100873 0.0217078 0.0222932 0.0132543 0.0193304 0.0179618 0.0150003 0.00728175 0.000336737 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
actual_catch[FishingLine]: 0 15.4607 30.9272 46.405 61.7825 77.1813 92.4877 107.939 123.187 138.585 153.901 169.255 184.649 199.967 215.329 230.617 246.071 261.456 276.773 292.143 307.568 323.051 338.474 353.96 369.512 385.012 400.585 416.111 431.836 447.521 463.171 478.909 493.16 542.251 716.892 188.334 76.7267 111.152 62.3206 89.4935 27.4252 81.8828 88.2938 135.39 371.378 420.873 474.391 650.028 577.468 650.8 696.286 598.872 632.214 303.699 308.709 328.839 504.835 437.154 409.319 369.165 548.767 426.63 490.973 464.628 342.137 229.096 271.427 382.412 352.846 257.159 323.169 284.632 147.75 415.765 354.769 168.15 191.067 154.386 153.356 114.114 249.337 256.121 151.593 221.612 200.035 157.185 69.689 2.92268 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
retained_catch[FishingLine]: 0 13.2 26.4 39.6 52.7 65.8 78.8 91.9 104.8 117.8 130.7 143.6 156.5 169.3 182.1 194.8 207.6 220.3 232.9 245.5 258.1 270.7 283.2 295.7 308.2 320.6 333 345.3 357.7 370 382.2 394.4 405.3 444.7 586.5 153.5 62.5 90.7 51 73.5 22.6 67.7 73.2 112.5 309.1 350.3 394.4 539.3 477.4 536 571 488.8 513.9 245.9 249.7 266.1 409 354.2 331.6 299 444.5 345.2 397 375.3 276.1 184.9 219.4 309.7 286.1 208.7 262.6 231.5 120.3 339.2 289.6 137.3 156.2 126.4 125.8 93.8 205.4 211.2 125 183 167.6 135.1 61.2 2.6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
actual_retained_catch[FishingLine]: 0 13.2 26.4 39.6 52.7 65.8 78.8 91.9 104.8 117.8 130.7 143.6 156.5 169.3 182.1 194.8 207.6 220.3 232.9 245.5 258.1 270.7 283.2 295.7 308.2 320.6 333 345.3 357.7 370 382.2 394.4 405.3 444.7 586.5 153.5 62.5 90.7 51 73.5 22.6 67.7 73.2 112.5 309.1 350.3 394.4 539.3 477.4 536 571 488.8 513.9 245.9 249.7 266.1 409 354.2 331.6 299 444.5 345.2 397 375.3 276.1 184.9 219.4 309.7 286.1 208.7 262.6 231.5 120.3 339.2 289.6 137.3 156.2 126.4 125.8 93.8 205.4 211.2 125 183 167.6 135.1 61.2 2.6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
discards[FishingLine]: 0 2.26073 4.52718 6.80499 9.08247 11.3813 13.6877 16.0392 18.3866 20.7846 23.2008 25.6549 28.1493 30.6673 33.2289 35.8174 38.4714 41.1561 43.8732 46.6431 49.4681 52.3506 55.274 58.2601 61.3119 64.4125 67.5845 70.8109 74.1356 77.5212 80.9707 84.5093 87.8599 97.5511 130.392 34.8341 14.2267 20.4521 11.3206 15.9935 4.82521 14.1828 15.0938 22.8899 62.2778 70.5731 79.991 110.728 100.068 114.8 125.286 110.072 118.314 57.7992 59.0087 62.7387 95.8353 82.9539 77.7185 70.1653 104.267 81.4298 93.9731 89.3277 66.0368 44.1958 52.0267 72.7118 66.746 48.4589 60.569 53.1317 27.4503 76.5647 65.1694 30.8502 34.8671 27.9858 27.5561 20.3135 43.9366 44.9208 26.5927 38.6121 32.4351 22.0849 8.48897 0.322681 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
discards_dead[FishingLine]: 0 2.26073 4.52718 6.80499 9.08247 11.3813 13.6877 16.0392 18.3866 20.7846 23.2008 25.6549 28.1493 30.6673 33.2289 35.8174 38.4714 41.1561 43.8732 46.6431 49.4681 52.3506 55.274 58.2601 61.3119 64.4125 67.5845 70.8109 74.1356 77.5212 80.9707 84.5093 87.8599 97.5511 130.392 34.8341 14.2267 20.4521 11.3206 15.9935 4.82521 14.1828 15.0938 22.8899 62.2778 70.5731 79.991 110.728 100.068 114.8 125.286 110.072 118.314 57.7992 59.0087 62.7387 95.8353 82.9539 77.7185 70.1653 104.267 81.4298 93.9731 89.3277 66.0368 44.1958 52.0267 72.7118 66.746 48.4589 60.569 53.1317 27.4503 76.5647 65.1694 30.8502 34.8671 27.9858 27.5561 20.3135 43.9366 44.9208 26.5927 38.6121 32.4351 22.0849 8.48897 0.322681 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
fishing_pressure[FishingPot]: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.00319603 0.00763937 0.00815656 0.0197831 0.0305091 0.0453553 0.0500428 0.0603524 0.0760016 0.0703881 0.105087 0.161064 0.145604 0.183013 0.212921 0.20709 0.199559 0.185037 0.148756 0.161514 0.141572 0.166363 0.156534 0.135482 0.123828 0.154589 0.178352 0.170563 0.18444 0.186552 0.181277 0.178547 0.169702 0.174499 0.180303 0.156298 0.161396 0.172455 0.133107 0.155948
actual_catch[FishingPot]: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 33.4624 80.0335 85.0555 207.069 313.488 444.721 452.839 497.664 564.507 463.642 623.037 849.038 676.063 826.911 997.749 1040.09 1063.59 1007.98 814.449 922.805 853.151 1067.26 1011.22 864.074 777.46 958.574 1054.68 937.768 979.686 962.038 894.406 850.9 789.682 801.265 810.571 704.919 749.632 805.604 602.377 694.514
retained_catch[FishingPot]: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 29.2 69.9 74.3 180.9 275.1 396.3 409.9 455.5 519.3 425.7 566.9 756.2 576.6 660.5 738.2 739.3 767.9 749.9 617.8 698.4 636.7 807.7 782.9 683 625.3 775.7 856.5 759.6 773.7 751.8 704.7 665.7 614.4 623.9 631 535.6 572.2 623.5 475.2 557
actual_retained_catch[FishingPot]: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 29.2 69.9 74.3 180.9 275.1 396.3 409.9 455.5 519.3 425.7 566.9 756.2 576.6 660.5 738.2 739.3 767.9 749.9 617.8 698.4 636.7 807.7 782.9 683 625.3 775.7 856.5 759.6 773.7 751.8 704.7 665.7 614.4 623.9 631 535.6 572.2 623.5 475.2 557
discards[FishingPot]: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4.2624 10.1335 10.7555 26.1688 38.3883 48.4213 42.9387 42.1638 45.2071 37.9417 56.1369 92.8382 99.4631 166.411 259.549 300.792 295.689 258.075 196.649 224.405 216.451 259.563 228.316 181.074 152.16 182.874 198.183 178.168 205.986 210.238 189.706 185.2 175.282 177.365 179.571 169.319 177.432 182.104 127.177 137.514
discards_dead[FishingPot]: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4.2624 10.1335 10.7555 26.1688 38.3883 48.4213 42.9387 42.1638 45.2071 37.9417 56.1369 92.8382 99.4631 166.411 259.549 300.792 295.689 258.075 196.649 224.405 216.451 259.563 228.316 181.074 152.16 182.874 198.183 178.168 205.986 210.238 189.706 185.2 175.282 177.365 179.571 169.319 177.432 182.104 127.177 137.514
fishing_pressure[Recreation]: 0 0.0018664 0.00192066 0.00196891 0.00202753 0.00208004 0.0021346 0.00219957 0.00225825 0.00232747 0.0023903 0.0024552 0.0024784 0.00252046 0.00255512 0.00260016 0.00263763 0.00268572 0.00272612 0.00277739 0.00282083 0.00288516 0.00295164 0.00302035 0.00309139 0.00316489 0.00324095 0.00330921 0.00337995 0.00344253 0.00351854 0.00359748 0.00371364 0.00383389 0.00398319 0.00419119 0.00418507 0.00407055 0.00396118 0.0038545 0.00376808 0.00366237 0.00357425 0.00349746 0.00344168 0.00344719 0.00348007 0.00362505 0.00383144 0.00403127 0.00425097 0.00449472 0.00466149 0.00482751 0.0048388 0.00484301 0.00485333 0.00503769 0.00520631 0.00536231 0.00548374 0.00571876 0.00583641 0.00600472 0.00614435 0.00621727 0.00620303 0.00616577 0.00618884 0.00621248 0.0061702 0.0061833 0.0061531 0.00605994 0.006114 0.00615076 0.00607147 0.00598598 0.0058868 0.00579541 0.00568254 0.00567413 0.00566636 0.00561175 0.00565899 0.00581268 0.00616832 0.00665498 0.00733278 0.00823098 0.00918538 0.0105212 0.0123434 0.0134929 0.0139802 0.0135279 0.01218 0.0114039 0.0109243 0.0102959 0.00977005 0.00912899 0.00890287 0.00888438 0.00887505 0.00890784 0.00924456 0.00996962 0.0105828 0.0110851 0.0115881 0.0122059 0.0125918 0.0127743 0.0131204 0.0134742 0.0131259 0.012941 0.0132134 0.0131324
actual_catch[Recreation]: 0 26.066 26.7527 27.3284 28.0211 28.6028 29.1873 29.8884 30.4781 31.1845 31.7793 32.3766 32.4039 32.6619 32.8069 33.0683 33.2165 33.4813 33.6328 33.901 34.0557 34.4432 34.833 35.2251 35.6196 36.0167 36.4165 36.7024 36.9909 37.1651 37.4587 37.7552 38.407 39.0631 39.8484 40.56 41.1797 41.1328 40.9249 40.807 40.6928 40.4636 40.1366 39.8258 39.5358 39.1799 38.9773 39.8551 40.7844 41.8472 42.8184 43.8119 44.4379 44.9421 45.4684 45.9382 46.3747 47.6759 49.1052 50.5409 51.8472 53.3175 54.299 55.4181 56.4158 57.4886 58.3773 58.7657 59.0608 59.4883 59.7827 60.21 60.3929 60.6513 60.854 61.1897 61.3678 61.2958 61.2007 61.0981 60.8708 60.815 60.4589 60.0295 59.1069 57.6214 56.2711 55.2997 54.9739 54.9028 55.4584 57.0835 60.1438 65.4818 71.3252 73.4348 69.1546 65.5949 63.2652 62.7038 62.6312 61.66 60.09 58.8749 57.8576 57.336 56.7018 57.3574 59.132 59.8443 59.9205 61.0865 61.611 61.5376 62.4341 64.3966 64.2229 63.2124 62.1673 60.9424
retained_catch[Recreation]: 0 22.9 23.5 24 24.6 25.1 25.6 26.2 26.7 27.3 27.8 28.3 28.3 28.5 28.6 28.8 28.9 29.1 29.2 29.4 29.5 29.8 30.1 30.4 30.7 31 31.3 31.5 31.7 31.8 32 32.2 32.7 33.2 33.8 34.3 34.8 34.8 34.7 34.7 34.7 34.6 34.4 34.2 34 33.7 33.5 34.2 34.9 35.7 36.4 37.1 37.5 37.8 38.2 38.6 39 40.1 41.3 42.5 43.6 44.8 45.6 46.5 47.3 48.2 49 49.4 49.7 50.1 50.4 50.8 51 51.3 51.5 51.8 52 52 52 52 51.9 51.9 51.6 51.3 51 50.7 50.4 50.1 50 49.7 49.5 49.4 49 49 49 48.9 47.3 46.5 45.6 44.8 44.3 44.6 44.7 44.9 44.9 44.8 44.5 44.5 44.6 44.9 45.2 45.7 45.8 45.9 46.1 46.5 46.8 47 47.3 47
actual_retained_catch[Recreation]: 0 22.9 23.5 24 24.6 25.1 25.6 26.2 26.7 27.3 27.8 28.3 28.3 28.5 28.6 28.8 28.9 29.1 29.2 29.4 29.5 29.8 30.1 30.4 30.7 31 31.3 31.5 31.7 31.8 32 32.2 32.7 33.2 33.8 34.3 34.8 34.8 34.7 34.7 34.7 34.6 34.4 34.2 34 33.7 33.5 34.2 34.9 35.7 36.4 37.1 37.5 37.8 38.2 38.6 39 40.1 41.3 42.5 43.6 44.8 45.6 46.5 47.3 48.2 49 49.4 49.7 50.1 50.4 50.8 51 51.3 51.5 51.8 52 52 52 52 51.9 51.9 51.6 51.3 51 50.7 50.4 50.1 50 49.7 49.5 49.4 49 49 49 48.9 47.3 46.5 45.6 44.8 44.3 44.6 44.7 44.9 44.9 44.8 44.5 44.5 44.6 44.9 45.2 45.7 45.8 45.9 46.1 46.5 46.8 47 47.3 47
discards[Recreation]: 0 3.16604 3.25275 3.32844 3.42107 3.50279 3.58726 3.68842 3.77811 3.88454 3.97933 4.07663 4.10393 4.16187 4.2069 4.26829 4.31651 4.38132 4.43275 4.50104 4.55575 4.64323 4.73298 4.82508 4.91962 5.01671 5.11645 5.20243 5.29091 5.36513 5.45874 5.5552 5.70702 5.86306 6.04836 6.26001 6.37973 6.33278 6.22485 6.107 5.99283 5.86358 5.7366 5.62579 5.53575 5.47992 5.47731 5.65507 5.88442 6.14717 6.41842 6.71188 6.93792 7.14207 7.26838 7.33823 7.37475 7.5759 7.80524 8.04091 8.24723 8.51748 8.69898 8.91811 9.1158 9.28862 9.37735 9.36573 9.36075 9.38827 9.38273 9.41 9.39286 9.35131 9.35399 9.38971 9.36781 9.29581 9.20066 9.09813 8.97079 8.91503 8.85888 8.7295 8.10692 6.92144 5.8711 5.19971 4.97393 5.20281 5.95835 7.68354 11.1438 16.4818 22.3252 24.5348 21.8546 19.0949 17.6652 17.9038 18.3312 17.06 15.39 13.9749 12.9576 12.536 12.2018 12.8574 14.532 14.9443 14.7205 15.3865 15.811 15.6376 16.3341 17.8966 17.4229 16.2124 14.8673 13.9424
discards_dead[Recreation]: 0 3.16604 3.25275 3.32844 3.42107 3.50279 3.58726 3.68842 3.77811 3.88454 3.97933 4.07663 4.10393 4.16187 4.2069 4.26829 4.31651 4.38132 4.43275 4.50104 4.55575 4.64323 4.73298 4.82508 4.91962 5.01671 5.11645 5.20243 5.29091 5.36513 5.45874 5.5552 5.70702 5.86306 6.04836 6.26001 6.37973 6.33278 6.22485 6.107 5.99283 5.86358 5.7366 5.62579 5.53575 5.47992 5.47731 5.65507 5.88442 6.14717 6.41842 6.71188 6.93792 7.14207 7.26838 7.33823 7.37475 7.5759 7.80524 8.04091 8.24723 8.51748 8.69898 8.91811 9.1158 9.28862 9.37735 9.36573 9.36075 9.38827 9.38273 9.41 9.39286 9.35131 9.35399 9.38971 9.36781 9.29581 9.20066 9.09813 8.97079 8.91503 8.85888 8.7295 8.10692 6.92144 5.8711 5.19971 4.97393 5.20281 5.95835 7.68354 11.1438 16.4818 22.3252 24.5348 21.8546 19.0949 17.6652 17.9038 18.3312 17.06 15.39 13.9749 12.9576 12.536 12.2018 12.8574 14.532 14.9443 14.7205 15.3865 15.811 15.6376 16.3341 17.8966 17.4229 16.2124 14.8673 13.9424
*end

*partition_mean_length[growth_length_at_age]
time_step: 1
male {L}
mean_lengths {d}
year 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
2019 23.8739 28.1259 31.6071 34.4573 36.7908 38.7014 40.2656 41.5463 42.5948 43.4533 44.1561 44.7315 45.2027 45.5884 45.9042 46.1628 46.3745 46.5478
end {L}
female {L}
mean_lengths {d}
year 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
2019 20.3404 23.898 26.8401 29.273 31.2849 32.9487 34.3246 35.4624 36.4034 37.1815 37.8249 38.357 38.7971 39.161 39.4619 39.7107 39.9165 40.0867
end {L}
*end

*partition_mean_weight[growth_weight_at_age]
time_step: 1
male {L}
mean_weights {d}
year 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
2019 0.00197186 0.00332922 0.00483168 0.00636232 0.00783752 0.00920477 0.0104363 0.0115219 0.0124631 0.0132687 0.013951 0.0145241 0.015002 0.0153981 0.0157249 0.015993 0.0162122 0.0163906
end {L}
female {L}
mean_weights {d}
year 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
2019 0.00118001 0.00197826 0.00287018 0.00379057 0.00469074 0.00553829 0.00631434 0.00701014 0.00762399 0.00815878 0.00862007 0.00901485 0.00935058 0.00963463 0.00987397 0.010075 0.0102433 0.0103839
end {L}
*end

*selectivity[potSSelm]
a50: 3.03962
alpha: 1
ato95: 0.192075
intervals: 5
label: potSurveySel_male
length_based: 0
partition_type: model
type: logistic
Values {v}
3 0.352662
4 1
5 1
6 1
7 1
8 1
9 1
10 1
11 1
12 1
13 1
14 1
15 1
16 1
17 1
18 1
19 1
20 1
*end

*selectivity[potSSelf]
a50: 3.3145
alpha: 1
ato95: 1.03325
intervals: 5
label: potSurveySel_female
length_based: 0
partition_type: model
type: logistic
Values {v}
3 0.289829
4 0.875823
5 0.991863
6 0.999526
7 0.999973
8 0.999998
9 1
10 1
11 1
12 1
13 1
14 1
15 1
16 1
17 1
18 1
19 1
20 1
*end

*observation[pot_survey]
observation_type: abundance
likelihood: lognormal
Values {d}
year category age length observed expected residual error_value process_error adjusted_error score pearsons_residuals
2010 male+female 0 0 11.066 14.0718 -3.00584 0.125 0.2 0.23585 -1.03819 -0.905691
2014 male+female 0 0 17.568 14.5455 3.02255 0.135 0.2 0.241299 -1.01953 0.861174
2018 male+female 0 0 12.532 11.9224 0.609601 0.215 0.2 0.293641 -1.19591 0.174127
*end

*observation[CPUE]
observation_type: biomass
likelihood: lognormal
Values {d}
year category age length observed expected residual error_value process_error adjusted_error score pearsons_residuals
1990 male+female 0 0 1.01179 1.27462 -0.262832 0.05 0.1 0.111803 -0.161596 -1.84435
1991 male+female 0 0 0.812523 1.08826 -0.27574 0.05 0.1 0.111803 1.09772 -2.26627
1992 male+female 0 0 0.789768 0.940162 -0.150394 0.05 0.1 0.111803 -1.05674 -1.43078
1993 male+female 0 0 0.800867 0.865162 -0.0642943 0.05 0.1 0.111803 -1.99117 -0.664691
1994 male+female 0 0 0.814346 0.848992 -0.0346457 0.05 0.1 0.111803 -2.14353 -0.364999
1995 male+female 0 0 0.844336 0.894933 -0.0505972 0.05 0.1 0.111803 -2.08534 -0.505685
1996 male+female 0 0 0.968863 0.96141 0.00745312 0.05 0.1 0.111803 -2.18631 0.0693385
1997 male+female 0 0 1.07802 1.00508 0.0729444 0.05 0.1 0.111803 -1.95996 0.64914
1998 male+female 0 0 1.0632 1.03788 0.0253272 0.05 0.1 0.111803 -2.15712 0.218266
1999 male+female 0 0 0.955824 1.07577 -0.119944 0.05 0.1 0.111803 -1.68919 -0.997249
2000 male+female 0 0 1.12167 1.13757 -0.0158945 0.05 0.1 0.111803 -2.19164 -0.124973
2001 male+female 0 0 1.23278 1.20713 0.0256528 0.05 0.1 0.111803 -2.16426 0.190076
2002 male+female 0 0 1.30543 1.23528 0.0701405 0.05 0.1 0.111803 -2.04219 0.507863
2003 male+female 0 0 1.26698 1.2456 0.0213721 0.05 0.1 0.111803 -2.17241 0.153466
2004 male+female 0 0 1.22875 1.24509 -0.0163384 0.05 0.1 0.111803 -2.19215 -0.117369
2005 male+female 0 0 1.31587 1.21709 0.0987839 0.05 0.1 0.111803 -1.90843 0.725955
2006 male+female 0 0 1.26358 1.1506 0.112984 0.05 0.1 0.111803 -1.79259 0.878294
2007 male+female 0 0 1.08656 1.07027 0.0162911 0.05 0.1 0.111803 -2.17583 0.136146
2008 male+female 0 0 1.01899 1.01293 0.00606264 0.05 0.1 0.111803 -2.18815 0.0535336
2009 male+female 0 0 1.03144 0.977816 0.0536236 0.05 0.1 0.111803 -2.05115 0.490506
2010 male+female 0 0 0.895963 0.940444 -0.0444808 0.05 0.1 0.111803 -2.1223 -0.423043
2011 male+female 0 0 0.984095 0.905809 0.0782864 0.05 0.1 0.111803 -1.87455 0.773028
2012 male+female 0 0 0.975651 0.885582 0.0900693 0.05 0.1 0.111803 -1.76652 0.90969
2013 male+female 0 0 0.960914 0.873143 0.0877711 0.05 0.1 0.111803 -1.77539 0.899107
2014 male+female 0 0 1.00118 0.850335 0.150843 0.05 0.1 0.111803 -1.03756 1.58664
2015 male+female 0 0 0.928886 0.852287 0.0765998 0.05 0.1 0.111803 -1.85141 0.803872
2016 male+female 0 0 0.917794 0.878065 0.0397286 0.05 0.1 0.111803 -2.09163 0.404689
2017 male+female 0 0 0.922603 0.885424 0.0371787 0.05 0.1 0.111803 -2.10391 0.375568
2018 male+female 0 0 0.758655 0.88219 -0.123535 0.05 0.1 0.111803 -1.35197 -1.25249
*end

*observation[LFlogbook]
observation_type: proportions_at_length
likelihood: multinomial
Values {d}
year category age length observed expected residual error_value process_error adjusted_error score pearsons_residuals
2010 male+female 0 13 0 4.40958e-07 -4.40958e-07 100 0 100 0 -0.00664047
2010 male+female 0 14 0 1.10182e-06 -1.10182e-06 100 0 100 0 -0.0104968
2010 male+female 0 15 0 2.87274e-06 -2.87274e-06 100 0 100 0 -0.0169492
2010 male+female 0 16 0 7.75047e-06 -7.75047e-06 100 0 100 0 -0.0278398
2010 male+female 0 17 0 2.12994e-05 -2.12994e-05 100 0 100 0 -0.0461518
2010 male+female 0 18 0 5.83248e-05 -5.83248e-05 100 0 100 0 -0.0763729
2010 male+female 0 19 0 0.000155441 -0.000155441 100 0 100 0 -0.124686
2010 male+female 0 20 0 0.000395381 -0.000395381 100 0 100 0 -0.198881
2010 male+female 0 21 0 0.000944554 -0.000944554 100 0 100 0 -0.307481
2010 male+female 0 22 0 0.00208342 -0.00208342 100 0 100 0 -0.456921
2010 male+female 0 23 0 0.00417474 -0.00417474 100 0 100 0 -0.647475
2010 male+female 0 24 0 0.00755524 -0.00755524 100 0 100 0 -0.872511
2010 male+female 0 25 0 0.0124151 -0.0124151 100 0 100 0 -1.12121
2010 male+female 0 26 0.000289101 0.0187221 -0.018433 100 0 100 0.0989964 -1.35995
2010 male+female 0 27 0.00289101 0.0261534 -0.0232624 100 0 100 0.947156 -1.45762
2010 male+female 0 28 0.00462561 0.0341024 -0.0294768 100 0 100 1.44123 -1.62413
2010 male+female 0 29 0.0118531 0.0421224 -0.0302693 100 0 100 3.84311 -1.50692
2010 male+female 0 30 0.0153223 0.0498775 -0.0345552 100 0 100 4.90153 -1.58734
2010 male+female 0 31 0.022839 0.0566625 -0.0338235 100 0 100 7.52674 -1.46298
2010 male+female 0 32 0.0297774 0.0625842 -0.0328068 100 0 100 10.0159 -1.35446
2010 male+female 0 33 0.0760335 0.0668292 0.00920433 100 0 100 30.3367 0.368577
2010 male+female 0 34 0.082972 0.0689478 0.0140241 100 0 100 33.436 0.553515
2010 male+female 0 35 0.100607 0.0692118 0.0313953 100 0 100 42.1153 1.23694
2010 male+female 0 36 0.113328 0.0667897 0.0465378 100 0 100 48.9886 1.86407
2010 male+female 0 37 0.0913559 0.0627271 0.0286288 100 0 100 38.4042 1.18071
2010 male+female 0 38 0.10292 0.057218 0.0457019 100 0 100 45.2394 1.96772
2010 male+female 0 39 0.0777681 0.0511222 0.0266459 100 0 100 33.2544 1.20982
2010 male+female 0 40 0.0526164 0.0449417 0.00767465 100 0 100 21.5636 0.370441
2010 male+female 0 41 0.0436542 0.0391349 0.00451935 100 0 100 17.89 0.233057
2010 male+female 0 42 0.0416305 0.033816 0.00781448 100 0 100 17.526 0.432324
2010 male+female 0 43 0.0222608 0.0289468 -0.00668606 100 0 100 8.797 -0.398794
2010 male+female 0 44 0.0268864 0.0244012 0.00248517 100 0 100 11.3981 0.16107
2010 male+female 0 45 0.0141659 0.0200275 -0.00586156 100 0 100 5.76757 -0.418401
2010 male+female 0 46 0.0121422 0.0157892 -0.00364701 100 0 100 5.14186 -0.292558
2010 male+female 0 47 0.0153223 0.0118015 0.00352086 100 0 100 7.11 0.32603
2010 male+female 0 48 0.0104076 0.00827105 0.00213658 100 0 100 5.00822 0.235908
2010 male+female 0 49 0.00636022 0.0053933 0.000966916 100 0 100 3.21419 0.132019
2010 male+female 0 50 0.00751662 0.00323439 0.00428224 100 0 100 4.22598 0.754186
2010 male+female 0 51 0.00375831 0.00176864 0.00198967 100 0 100 2.26402 0.473529
2010 male+female 0 52 0.00520382 0.000882655 0.00432116 100 0 100 3.53978 1.45511
2010 male+female 0 53 0.00260191 0.000406824 0.00219508 100 0 100 1.93082 1.08852
2010 male+female 0 54 0.0011564 0.000176592 0.000979812 100 0 100 0.943 0.737388
2010 male+female 0 55 0.000289101 7.37956e-05 0.000215305 100 0 100 0.259047 0.250643
2010 male+female 0 56 0.000867303 3.02955e-05 0.000837007 100 0 100 0.858264 1.52071
2010 male+female 0 57 0.000289101 1.24197e-05 0.000276681 100 0 100 0.310566 0.785105
2010 male+female 0 58 0.000289101 5.14567e-06 0.000283955 100 0 100 0.336039 1.25179
*end

*estimate_summary[estimated_summary]
process[Recruitment].b0 {L}
value: 14199.6
std_dev: 1
estimation_phase:
label: B0
lower_bound: 100
mcmc:
parameter: process[Recruitment].b0
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: uniform_log
upper_bound: 250000
end {L}

age_length[asMm0].linf {L}
value: 47.3306
std_dev: 1
estimation_phase:
label: male_Linf
lower_bound: 30
mcmc:
parameter: age_length[asMm0].linf
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: uniform
upper_bound: 70
end {L}

age_length[asMm0].cv_last {L}
value: 0.0597765
std_dev: 1
estimation_phase:
label: male_cv2
lower_bound: 0.02
mcmc:
parameter: age_length[asMm0].cv_last
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: uniform
upper_bound: 1.0
end {L}

selectivity[potSurveySel_male].a50 {L}
value: 3.03962
std_dev: 1
estimation_phase:
label: potSurvey_mA50
lower_bound: 1
mcmc:
parameter: selectivity[potSurveySel_male].a50
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: uniform
upper_bound: 7
end {L}

selectivity[potSurveySel_male].ato95 {L}
value: 0.192075
std_dev: 1
estimation_phase:
label: potSurvey_mAto95
lower_bound: .1
mcmc:
parameter: selectivity[potSurveySel_male].ato95
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: uniform
upper_bound: 5
end {L}

selectivity[potSurveySel_female].a50 {L}
value: 3.3145
std_dev: 1
estimation_phase:
label: potSurvey_fA50
lower_bound: 1
mcmc:
parameter: selectivity[potSurveySel_female].a50
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: uniform
upper_bound: 7
end {L}

selectivity[potSurveySel_female].ato95 {L}
value: 1.03325
std_dev: 1
estimation_phase:
label: potSurvey_fAto95
lower_bound: .1
mcmc:
parameter: selectivity[potSurveySel_female].ato95
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: uniform
upper_bound: 5
end {L}

process[Recruitment].ycs_values{1980} {L}
value: 0.235225
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1980}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1981} {L}
value: 0.232175
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1981}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1982} {L}
value: 0.233214
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1982}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1983} {L}
value: 0.24199
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1983}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1984} {L}
value: 0.264644
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1984}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1985} {L}
value: 0.314841
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1985}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1986} {L}
value: 0.416172
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1986}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1987} {L}
value: 0.601743
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1987}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1988} {L}
value: 0.902116
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1988}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1989} {L}
value: 1.37833
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1989}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1990} {L}
value: 1.56001
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1990}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1991} {L}
value: 1.02891
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1991}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1992} {L}
value: 0.847878
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1992}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1993} {L}
value: 0.846852
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1993}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1994} {L}
value: 1.06536
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1994}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1995} {L}
value: 1.54897
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1995}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1996} {L}
value: 1.05327
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1996}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1997} {L}
value: 0.803063
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1997}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1998} {L}
value: 0.816688
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1998}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{1999} {L}
value: 0.628379
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{1999}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2000} {L}
value: 0.802062
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2000}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2001} {L}
value: 0.745814
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2001}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2002} {L}
value: 0.467129
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2002}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2003} {L}
value: 1.09423
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2003}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2004} {L}
value: 0.921275
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2004}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2005} {L}
value: 0.384129
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2005}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2006} {L}
value: 0.905891
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2006}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2007} {L}
value: 0.709813
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2007}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2008} {L}
value: 0.835569
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2008}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2009} {L}
value: 0.426295
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2009}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2010} {L}
value: 1.28746
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2010}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2011} {L}
value: 0.690332
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2011}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2012} {L}
value: 0.736378
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2012}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2013} {L}
value: 0.561556
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2013}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

process[Recruitment].ycs_values{2014} {L}
value: 0.439783
std_dev: 1
cv: 0.6
estimation_phase:
label: YCS
lower_bound: 0.1
mcmc:
mu: 1
parameter: process[Recruitment].ycs_values{2014}
prior_applies_to_transform:
same:
transform_with_jacobian:
transformation:
type: lognormal
upper_bound: 10
end {L}

*end

*hessian_matrix[Hess]
hessian_matrix {m}
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*end

*covariance_matrix[Covar]
covariance_matrix {m}
1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
*end

*correlation_matrix[Corr]
correlation_matrix {m}
1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
*end

*catchability[Qs]
potSurveyq: 1.15696e-05
potCPUEq: 0.000240494
*end

*warnings[warnings_encounted]
warnings_found: 1
warning_0 {s}
Estimates were removed because of matching lower and upper bounds. Originally had 127 estimates, now have 42
*end

Total elapsed time: 10.317 minutes
Completed

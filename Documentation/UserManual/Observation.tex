\section{The observation section: observations and their likelihoods\label{sec:Observation}}

The command and subcommand syntax for the estimation section is given in Section \ref{syntax:Observation}.

\subsection{\I{Observations}\index{Observations}}

The objective function calculates the goodness-of-fit of the model to the observation data. Observations are typically supplied at an instance in time, over a group of aggregated categories. Most observations are sampled over time, i.e., data which were recorded for one or more years, in the same format each year. Examples of time series data types include relative abundance indices, commercial catch length frequencies, and survey \ifAgeBased numbers-at-age. \else numbers-at-length. \fi

Definitions for each type of observation are described below, including how the observed values should be formatted, how \CNAME\ calculates the expected values, and the likelihoods that are available for each type of observation.

There are two main types of observations available in \CNAME. The first type is observations that are associated with a process, and the second are associated with a mortality block (See Section \ref{sec:Process-Mortality}.

Observations for a process are indicated by their type --- these use the word process as a part of the type name, e,.g., \defComArg{observation}{type}{abundance} is an observation of relative abundance that occurs during a mortality block within a time step, and \defComArg{observation}{type}{process\_abundance} is a observation  of relative abundance that occurs during a process within a time step.

\subsubsection{\I{Mortality block associated observations}}\label{sec:MortalityBlockObservations}

All observations within this class are calculated similarly. That is, the expected values are calculated at the beginning of the mortality block and at the end of the mortality block. \CNAME\ then uses a linear interpolation to approximate the expected values part way through a mortality block using the subcommand \subcommand{time\_step\_proportion}. This feature could be useful if a survey occurs part way through an exploitation phase, which may be part way through a fishing season when modelling a fish population. Each observation in this class will evaluate different expectations of the partition (explained in the following descriptions).

The observation \texttt{types} available with this class of observations are:

\begin{itemize}
	\item \subcommand{abundance}
	\item \subcommand{biomass}
	\ifAgeBased
	\item \subcommand{proportions\_at\_age}
	\fi
	\item \subcommand{proportions\_at\_length}
	\item \subcommand{proportions\_by\_category}
	\item \subcommand{tag\_recapture\_by\_length}
	\ifAgeBased
	\item \subcommand{tag\_recapture\_by\_age}
	\fi
\end{itemize}

\paragraph*{\I{Abundance or biomass observations}}\label{sec:Observation-Abundance}\label{sec:Observation-Biomass}

Abundance (or biomass) observations are observations of either a relative or absolute number (or biomass) of individuals from a set of categories after applying a selectivity. The observation classes are the same, except that a biomass observation will use the biomass as the observed (and expected) value (calculated from mean weight of individuals within each \ifAgeBased age \else length \fi and category) while an abundance observation is the number of individuals.

Each observation is for a given year and time-step, for some selected \ifAgeBased age \else length \fi classes of the population (for a range of \ifAgeBased age \else length \fi classes multiplied by a selectivity), for aggregated categories. Furthermore, the label of the catchability coefficient $q$ is required;  $q$ can either be estimated of fixed. For absolute abundance or absolute biomass observations, define a catchability where $q=1$. Catchabilities can be estimated as either free parameters or as nuisance parameters (see Section \ref{subsec:catchabilities}).


The observations can be supplied for any set of categories. For example, for a model with the two categories \emph{male} and \emph{female}, an observation of the total abundance/biomass (male $+$ female) or male-only abundance/biomass could be provided. The subcommand \subcommand{categories} defines the categories used to aggregate the abundance/biomass. In addition, each category must have an associated selectivity, defined by \subcommand{selectivities}.

For example,

{\small{\begin{verbatim}
		categories male
		selectivities male-selectivity
\end{verbatim}}}

defines an observation for males after applying the selectivity male-selectivity. \CNAME\ then requires that an observation is supplied. The expected values for the observations will be the expected abundance (or biomass) of males, after applying the selectivities, at the year and time-step specified.

\CNAME\ calculates the expected values by summing over the defined \ifAgeBased age \else length \fi classes (via the \ifAgeBased age \else length \fi range and selectivity) and categories at both the beginning and end of a mortality block. \CNAME\ will approximate the expectation part way through the mortality block using the \texttt{time\_step\_proportion}. The default \texttt{time\_step\_proportion} value is 0.5. \CNAME\ does linear interpolation between the start and end abundance (or biomass) from the mortality block.

For an abundance observation the expected value is

\begin{equation}\label{eq:expec_1}
E_{i,1} = \sum_{c=1}^{} \sum_{a=1}^{A} S_{a,c} N_{a,c,i,1}
\end{equation}

\begin{equation}\label{eq:expec_2}
E_{i,2} = \sum_{c=1}^{} \sum_{a=1}^{A} S_a N_{a,c,i,2}
\end{equation}

Where $E_{i,1}$ is the expectation at the beginning of time step and $E_{i,2}$ is the expectation at the end of the time-step. $S_a$ is the selectivity for \ifAgeBased age \else length \fi $a$ and category $c$. If there is no mortality related to this observation then $E_i$ which is used in the likelihood contribution is $E_{i,1}$. If this was a biomass observation, then $N_{a,c,i,1}$ in Equations~\eqref{eq:expec_1} and~\eqref{eq:expec_2} is replaced with $N_{a,c,i,1} \bar{w}_{a,c}$, where $\bar{w}_{a,c}$ is the mean weight of category $c$ at \ifAgeBased age \else length \fi $a$. If the user wishes to apply 100\% mortality then $E_i = E_{i,2}$.

For applying quantities of mortality between these values ($M_i$), the linear interpolation is

\begin{equation}
E_{i} = |E_{i,1} - E_{i,2}|  M_i
\end{equation}

For each year of observations, the observation table \texttt{table obs} has a row with year in the first column, the observation per category in the middle column(s), and the error value in the final column:

{\small{\begin{verbatim}
@observation MyAbundance
type abundance
years 1999
...
categories male
table obs
1999 1000 0.10
end_table
...
\end{verbatim}}}

For an observation aggregated over multiple categories:

{\small{\begin{verbatim}
@observation MyAbundance
type abundance
years 1990 1991
...
categories male+female
table obs
1990 1000 0.10
1991 1200 0.12
end_table
		...
\end{verbatim}}}

For observations for multiple categories:

{\small{\begin{verbatim}
@observation MyAbundance
type abundance
years 1990 1991
...
categories male female
table obs
1990 550 450 0.10
1991 700 500 0.12
end_table
...
\end{verbatim}}}

To define a biomass observation instead of an abundance observation, use

{\small{\begin{verbatim}
@observation MyBiomass
type biomass
...
\end{verbatim}}}

\ifAgeBased
\paragraph*{\I{Proportions-at-age}}\label{sec:Observation-ProportionsAtAge}

Proportions-at-age observations are observations of the relative number of individuals at age, via some selectivity.

The observation is supplied for a given year and time-step, for some selected age classes of the population (i.e., for a range of ages multiplied by a selectivity). Note that the categories defined in the observations must have an associated selectivity, defined by \subcommand{selectivities}.

The age range must be ages defined in the partition (i.e., between \commandsub{model}{min\_age} and \commandsub{model}{max\_age} inclusive); the upper end of the age range can optionally be a plus group, which must be either the same as or less than the plus group defined for the partition.

Proportions-at-age observations can be supplied as

\begin{itemize}
	\item a set of proportions for a single category,
	\item a set of proportions for multiple categories, or
	\item a set of proportions across aggregated categories.
\end{itemize}

The method of evaluating expectations are the same for all three types of proportions. The definitions of these proportions and the expected dimensions of observation and error inputs that \CNAME\ expects for each respective proportion type are described below with examples.

Like all types of observations that are associated with the mortality block, \CNAME\ will evaluate the numbers at age before and after the mortality block for the specified time step of the observation, and applying the user-defined selectivity. \CNAME\ then generates the expectations from the partition part way through the mortality block using the subcommand \texttt{time\_step\_proportion}. This approximation is a linear interpolation of the numbers-at-age over the mortality block.

The ageing error is then applied, if the user has specified it. Finally, \CNAME\ converts the numbers-at-age to proportions-at-age by dividing all numbers in an age bin by the total numbers. The likelihood for the proportions-at-age observation is then calculated.

Defining an observation for a single category is used to model a set of proportions of a single category by age class. For example, to specify that the observations are of the proportions of male within each age class, then the subcommand \subcommand{categories} for the \commandlabsubarg{observation}{type}{proportion\_by\_age} command is

{\small{\begin{verbatim}
		categories male
		\end{verbatim}}}

\CNAME\ then requires that there will be a single vector of proportions supplied, with one proportion for each age class within the defined age range, and that these proportions sum to one.

For example, if the age range was 3 to 10, then 8 proportions should be supplied, one proportion for each of the ages 3, 4, 5, 6, 7, 8, 9, and 10. The expected values will be the expected proportions of males within each of these age classes (after omitting males aged less than 3 and older than 10), after applying a selectivity at the year and time-step specified. The supplied vector of proportions (i.e., in this example, the 8 proportions) must sum to one, which is evaluated with a default tolerance of 0.001.

{\small{\begin{verbatim}
		@observation MyProportions
		type proportions_at_age
		...
		categories male
		min_age 3
		max_age 9
		years 1990
		table obs
		1990 0.01 0.09 0.20 0.20 0.35 0.10 0.05
		end_table
		...
		\end{verbatim}}}

Defining an observation for multiple categories extends the single category observation definition. It is used to model a set of proportions over several categories by age class. For example, to specify that the observations are of the proportions of male or females within each age class, then the subcommand \subcommand{categories} for the \commandlabsubarg{observation}{type}{proportion\_by\_age} command is

{\small{\begin{verbatim}
		categories male female
		\end{verbatim}}}

\CNAME\ then requires that there will be a single vector of proportions supplied, with one proportion for each category and age class combination, and that these proportions sum to one across all ages and categories.

For example, if there were two categories and the age range was 3 to 10, then 16 proportions should be supplied (one proportion for each of the ages 3, 4, 5, 6, 7, 8, 9, and 10, for each category male and female). The expected values will be the expected proportions of males and females within each of these age classes (after omitting those aged less than 3 and older than 10), after applying a selectivity at the year and time-step specified. The supplied vector of proportions (i.e., in this example, the 16 proportions) must sum to one, which is evaluated with a default tolerance of 0.001.

For example,

{\small{\begin{verbatim}
		@observation MyProportions
		type proportions_at_age
		...
		categories male female
		min_age 1
		max_age 5
		years 1990 1991
		table obs
		1990 0.01 0.05 0.10 0.20 0.20 0.01 0.05 0.15 0.20 0.03
		1991 0.02 0.06 0.10 0.21 0.18 0.02 0.03 0.17 0.20 0.01
		end_table
		...
		\end{verbatim}}}

Defining an observation across aggregated categories allows categories to be aggregated before the proportions are calculated. It is used to model a set of proportions from several categories that have been combined by age class. To indicate that two (or more) categories are to be aggregated, separate them with a '+' symbol. For example, to specify that the observations are of the proportions of male and females combined within each age class, then the subcommand \subcommand{categories} for the \commandlabsubarg{observation}{type}{proportion\_by\_age} command is

{\small{\begin{verbatim}
		categories male + female
		\end{verbatim}}}

\CNAME\ then requires that there will be a single vector of proportions supplied, with one proportion for each age class, and that these proportions sum to one.

For example, if there were two categories and the age range was 3 to 10, then 8 proportions should be supplied (one proportion for each of the ages 3, 4, 5, 6, 7, 8, 9, and 10, for the sum of males and females within each age class). The expected values will be the expected proportions of males + females within each of these age classes (after omitting those aged less than 3 and older than 10), after applying a selectivity at the year and time-step specified. The supplied vector of proportions (i.e., in this example, the 8 proportions) must sum to one, which is evaluated with a default tolerance of 0.001.

For example,

{\small{\begin{verbatim}
		@observation MyProportions
		type proportions_at_age
		...
		years 1990 1991
		categories male+female
		min_age 1
		max_age 5
		table obs
		1990 0.02 0.13 0.25 0.30 0.30
		1991 0.02 0.06 0.18 0.35 0.39
		end_table
		...
		\end{verbatim}}}

The latter form can then be extended to include multiple categories, or multiple aggregated categories. For example, to describe proportions for the three groups: immature males, mature males, and all females (immature and mature females added together) for ages 1 through 4, a total of 12 proportions are required

{\small{\begin{verbatim}
		@observation MyProportions
		type proportions_at_age
		...
		categories male_immature male_mature female_immature+female_mature
		min_age 1
		max_age 4
		years 1990
		table obs
		year 1990 0.05 0.15 0.15 0.05 0.02 0.03 0.08 0.04 0.05 0.15 0.15 0.08
		end_table
		...
		\end{verbatim}}}

\paragraph*{\I{Proportions-at-length}}\label{sec:Observation-ProportionsAtLength}

Functionality for defining combinations of categories and aggregated categories directly translates from proportions-at-age to proportions-at-length. The difference is the observation is over length bins instead of age classes. \CNAME\ calculates the expected numbers-at-length by converting the numbers-at-age to numbers-at-length by using the age-length relationship and distribution specified for the category specified in the \command{age\_length} block.

Instead of supplying a minimum and maximum age, the user must supply a vector of length bins. If no length bins are specified, then the observation-specific length bins use the model length bins as the default. If observation-specific length bins are specified, they must be a sequential subset of the model length bins, with no missing or added values. For example, if the model length bins are \texttt{0 5 10 15 20 25 ... 100}, then the observation-specific length bins can be \texttt{20 25 30 35 40 45 50} but not \texttt{20 30 40 50}.

If there is no plus group, i.e., \texttt{length\_plus=false}, then \CNAME\ requires a vector of proportions for each year of length $n - 1$, where $n$ is the number of lengths supplied. If \texttt{length\_plus=true} then \CNAME\ expects a vector of proportions for each year of length $n$. The last proportion represents the numbers from the last length bin to the maximum length the age-length relationship allows.

{\small{\begin{verbatim}
		@observation Observed_Length_frequency_Chat_east
		type process_removals_by_length
		years 1991 1992
		likelihood multinomial
		time_step Summer
		fishery EastChathamRise
		mortality_process instant_mort
		categories male
		length_plus false
		length_bins 0 20 40 60 80 110
		table obs
		1991    0.2   0.25    0.15     0.2     0.2
		1992    0.12  0.25    0.28    0.25    0.1
		end_table
		table error_values
		1991 25
		1992 37
		end_table
		\end{verbatim}}}

\paragraph*{\I{Age-length}}\label{sec:Observation-AgeSize}
Age-length data are observations of the ages and lengths of individual fish. They are primarily used to fit length-at-age parameters in age-based models. 

The data include a list of ages, a list of lengths for a category or combination of categories, plus information on when, where, and how the observations were collected. So, the i\textsuperscript{th} elements of the lists contain the age and length of the i\textsuperscript{th} fish observed.

There are several possible sampling regimes, i.e., assumptions about how the observed fish were sampled from the general population of fish available at that time and place. The options are: 
\begin{itemize}
	\item \subcommand{random}: fish were a simple random sample from the available population
	\item \subcommand{age}: fish were a simple random sample within each age class 
	\item \subcommand{length}: fish were a simple random sample within each length class
\end{itemize}
We believe the \subcommand{age} option is quite unlikely to be true, yet they are widely applied in fisheries (for example, in the Coleraine \citep{hilborn2001coleraine} stock modelling software). Probably the \subcommand{length} option is most likely to hold for most New Zealand finfish programmes.

In age-length data, there should be no observations for which the age is outside the age range (\subcommand{min\_age} - \subcommand{max\_age}) defined for the partition (this will generate a fatal error message), nor any non-integer ages. Observations with ages below the minimum age in the partition should be removed. Observations where an age exceeds the maximum age in the partition could either be included in the plus group (i.e., with the observed age changed to that of the plus group) or removed, depending on the circumstances. If there is no plus group in the partition they should be removed. For \subcommand{age} samples they may be either included or removed in the plus group. For all other sample types they could be included in the plus group.

In addition, the user can specify a selectivity which was applied in the sampling process, perhaps due to the sampling gear that was used, or the areal availability of fish at that place or time. The selectivity can be age- or length-based: the choice has direct bearing on the likelihood of the observations. Under some sampling regimes, a length-based selectivity has no effect on the likelihood and hence should not be used (since it adds computational time). This occurs when the character on which the selectivity acts was not randomly chosen in the sample: for instance, if 10 fish of each category were chosen from each length class, then a length-based selectivity will have had no effect (except perhaps to make it easier/harder to find the 10 fish!). In general, a length-based selectivity has no effect under the \subcommand{length} method unless the selectivity is specified by category. If you attempt to use a length-based selectivity in this situation, \CNAME\ will issue a warning and will not apply the ogive. In cases where the length-based selectivity does have an effect, \CNAME\ will issue a warning that the selectivity adds to the computational time, and will apply it as requested.

Similarly, under some sampling regimes, an age-based selectivity has no effect on the likelihood, and should not be used. This applies under the \subcommand{age} method unless the selectivity is specified by age. If you attempt to use an age-based selectivity in this situation, \CNAME\ will issue a warning and not apply the selectivity. 

The user must additionally specify the year, time-step, and proportion of mortality when the observations were collected, and whether ageing error is to be applied. 

The only likelihood available for a single observation, is the Bernoulli distribution (\subcommand{bernoulli}), the other one is \subcommand{none} which will generate expected values but won't evaluate the likelihood.


A difference between CASAL and \CNAME\ is how to deal with sexes and categories. In CASAL sex was a hard coded attribute so it could generate numbers at age for a sex without any input from the user. \CNAME\ doesn't have this luxury and users are required to explicitly state the categories often that share the same age-length relationship using the \subcommand{numerator\_categories}. This is an optional parameter, and used when sex is an attribute in the partition along with other attributes such as maturity or tagging. If users do not specify \subcommand{numerator\_categories} it defaults to the categories supplied in \subcommand{categories}. The categories defined by \subcommand{numerator\_categories} are denoted by \(c^*\), where as categories defined by \subcommand{categories} represent the available population in the sampling process denoted by \(c\).

All categories listed in \subcommand{numerator\_categories} are required to have the same \command{age\_length} block as well as the same selectivity.


With a \subcommand{random} sample covering a single category \(c^*\) with ageing error the expected probability of sampling a fish with this age and length characteristic follows,

\[
P(a,l) = \bigg[\sum_{a^*} N^{c^*}_{a^*}M_{a^*,a}f_{a^*,c^*}(l)\bigg] / \bigg[\sum_{a^*}\sum_{c} N_{a^*,c}\bigg]
\]

where, \(N^{c^*}_{a^*}\) is the number of fish of true age \(a^*\) and categories \(c^*\), \(M_{a^*,a}\) is the probability that a fish of true age \(a^*\) is observed as age \(a\), and \(f^{c^*}_{a^*,c}(l)\) is the probability density function describing the distribution of sizes for a given (true) age \(a^*\) and age-length for categories \(c^*\). In this case with a single category \(c^* = c\). When there is no ageing error the numerator of the above equation simplifies to \(N^{c^*}_{a^*}f_{a^*,c^*}(l)\).

When multiple categories are supplied by \subcommand{numerator\_categories}, then \(N^{c^*}_{a^*}\) is calculated as

\[
N_{a^*,c^*} = \sum\limits_{\tilde{c} \in c^*} N_{a^*,\tilde{c}} S_c(a^*)
\]

where, \(S_c(a^*)\) is a selectivity and \(N_{a^*,c^*}\) is numbers at age from an interpolation partway through the mortality block.

For all the other sample types the expected value is a conditional probability, and is calculated as a fraction whose numerator is the same as for \(P(a,l) \) and with the denominator given in Table~\ref{tab:agelength:likelihoods}.

If the user specifies a selectivity for an age-length observation, this is easy to deal with if the selectivity is age-based. If \(N^*_{a^*,c}\) is the number at true age \(a^*\) and category \(c\) before the selectivity is applied then \(N_{a^*,c} = N^*_{a^*,c}S_c(a^*)\), where \(S_c(.)\) is the selectivity function for category \(c\).

It is more complicated with a length-based selectivity because of the need to distinguish between the distribution of length at age before [\(f^*_{a^*,c}(l)\)] and after [\(f_{a^*,c}(l)\)] the selectivity is applied (note: it is the former which is defined by the model parameters). The appropriate equations are
\[
f_{a^*,c}(l) = S_c(l)f^*_{a^*,c}(l) \ / \ \int_{l^*} S_c(l^*)f^*_{a^*,c}(l^*) dl^* \ ,
\]
and 
\[
N_{a^*,c} = N^*_{a^*,c} \int_{l^*} S_c(l^*)f^*_{a^*,c}(l^*) dl^* \ ,
\]
The integrals in these equations are calculated by discrete approximation (using 5 points), in the same way as length-based selectivities are converted to age-based selectivities.

The observed values are a one and the expected value is the probability (\(P(a,l)\))

\begin{table}[h!]
	\centering
	\caption{Age-Length likelihoods for the different sample types.}
	\label{tab:agelength:likelihoods}
	\begin{tabular}{|c | c | c | c|} 
		\hline
		Sample & Conditional probability & \multicolumn{2}{c}{Denominator} \\
		\multicolumn{2}{|c|}{} & Ageing Error & Without Ageing Error\\
		\hline\hline
		\subcommand{random} &\(L = P(a,l) \) & \(\sum_{a^*}\sum_{c} N_{a^*,c}\) & \(\sum_{a^*}\sum_{c} N_{a^*,c}\) \\ 
		\subcommand{by\_age} & \(L = P(l|a,c) \) & \(\sum_{a^*}\sum_{c} N_{a^*,c}M_{a^*,a}\) & \(\sum_{c} N_{a,c}\) \\
		\subcommand{by\_length} & \(L = P(a,c|l) \) & \(\sum_{a^*}\sum_{c} N_{a^*,c}f_{a^*,c}(l)\) &  \(\sum_{a^*}\sum_{c} N_{a^*,c}f_{a^*,c}(l)\)  \\
		\hline
	\end{tabular}
\end{table}

Currently \CNAME\ only allows the following \subcommand{sample\_type}'s  \subcommand{random},  \subcommand{age} and \subcommand{length}. These three can cover the following CASAL use cases \subcommand{random\_at\_sex\_and\_age} and  \subcommand{random\_at\_sex\_and\_size}, \subcommand{random} and  \subcommand{random\_at\_size}, and \subcommand{random\_at\_age}.


\CNAME\ distinguishes between \subcommand{random\_at\_sex\_and\_size} and \subcommand{random\_at\_size} by how the categories are defined in the observation block. For example, if there is a sexed model with Two categories male and female. To set up an observation that was \subcommand{random\_at\_size} for males you could define the following observation
{\small{\begin{verbatim}
	@observation male_age_length_obs
	type age_length
	year 1987
	likelihood bernoulli
	time_step step1
	time_step_proportion 0.5
	sample_type length
	categories male+female
	numerator_categories male
	selectivities One One
	ages   	6  8   9   9   9   9   9   9  11  12  12  12  12  13  14  
	lengths 	12.2 15.0 15.0 15.1 15.3 16.0 16.0 16.4 14.9 15.8 17.1 17.5 19.4 22.0 14.6 
	sample_type length
\end{verbatim}}}

However if you wanted to apply a \subcommand{random\_at\_sex\_and\_size} observation, then you change the \subcommand{categories} command as follows. This will calculate the probability of sampling a fish of age \(a\) conditional on it being a male and the given length.

{\small{\begin{verbatim}
		@observation male_age_length_obs
		type age_length
		year 1987
		likelihood bernoulli
		time_step step1
		time_step_proportion 0.5
		sample_type length
		categories male
		numerator_categories male
		selectivities One One
		ages   	6  8   9   9   9   9   9   9  11  12  12  12  12  13  14  
		lengths 	12.2 15.0 15.0 15.1 15.3 16.0 16.0 16.4 14.9 15.8 17.1 17.5 19.4 22.0 14.6 
		sample_type length
		\end{verbatim}}}

See Section~\ref{syntax:Observation-AgeLength} for more details on commands and syntax.

\paragraph*{\I{Proportions-by-category observations}}\label{sec:Observation-ProportionsByCategory}

\TODO{'between categories' or 'within categories'}

Proportions-by-category observations are observations of either the relative number of individuals between categories within age classes, or relative biomass between categories within age classes.

The observation is supplied for a given year and time-step, for selected age classes of the population (i.e., for a range of ages multiplied by a selectivity).

The age range must be ages defined in the partition (i.e., between \commandsub{model}{min\_age} and \commandsub{model}{max\_age} inclusive); the upper end of the age range can optionally be a plus group, which may or may not be the same as the plus group defined for the partition.

Proportions-by-category observations can be supplied for any set of categories as a proportion of themselves and any set of additional categories. For example, for a model with the two categories \emph{male} and \emph{female}, observations of the proportions of males in the population at each age class might be provided. The subcommand \subcommand{categories} defines the categories for the numerator in the calculation of the proportion, and the subcommand \subcommand{categories2} supplies the additional categories to be used in the denominator of the calculation. In addition, each category must have an associated selectivity, defined by \subcommand{selectivities} for the numerator categories and \subcommand{selectivities2} for the additional categories used in the denominator.

For example,

{\small{\begin{verbatim}
		categories male
		categories2 female
		selectivities male-selectivity
		selectivities2 female-selectivity
		\end{verbatim}}}

defines the proportion of males in each age class as a proportion of males $+$ females. \CNAME\ then requires that there will be a vector of proportions supplied, with one proportion for each age class within the defined age range, i.e., if the age range was 3 to 10, then 8 proportions should be supplied (one proportion for each of the the ages 3, 4, 5, 6, 7, 8, 9, and 10). The expected values will be the expected ratios of male to male $+$ female within each of these age classes, after applying the selectivities at the year and time-step specified.

\CNAME\ calculates the expected values by summing over the ages (via the age range and selectivity)

For example,

{\small{\begin{verbatim}
		@observation MyProportions
		type proportions_by_category
		years 1990 1991
		...
		categories male
		categories2 female
		min_age 1
		max_age 5
		table obs
		1990 0.01 0.05 0.10 0.20 0.20
		1991 0.02 0.06 0.10 0.21 0.18
		end_table
		...
		\end{verbatim}}}


\paragraph*{\I{Tag recaptures by age or length}\label{sec:Observation-TagRecaptures}\label{sec:Observation-TagRecaptureByAge}\label{sec:Observation-TagRecaptureByLength}}

Tag data is primarily used to estimate the population abundance of fish. In some models, this estimation can only be made outside the model and the result is used as an estimate of abundance in the model. But in \CNAME\ the tagging data can, alternatively, be fitted within the model.

Before adding a tag-recapture time series, a tag-release process (Section~\ref{sec:Process-TagByAge}) needs to be defined. Tagging events list the labels of the tags which are modelled, and define the events where fish are tagged (i.e., \CNAME\ moves fish into the section of the partition corresponding to a specific tag).

The observations are divided into two parts: (i) the number of fish that were scanned, and (ii) the number of tags that were recaptured. Each number can be specified by categories, or for combinations of categories. The precise content of the scanned and recaptured observations depends on the sampling method.

The options for tag-recaptures are available:

\begin{itemize}
	\item age: both the scanned and recaptured are vectors containing numbers-at-age. Only available in an age-based model. 
	\item size: both the scanned and recaptured are vectors containing numbers-at-length. Can be used in either an age- or length-based model.
\end{itemize}

When defining the tag-recapture time series, the following are also required:

\begin{itemize}
	\item the time step,
	\item the years (unlike a tag-release process, the tag-recapture observations can occur over several years),
	\item the probability that each scanned tagged fish is detected as tagged (may be less than 1 if the observers are not infallible). The expected number of tags detected is calculated by multiplying the expected number of tagged fish in the observation by the detection probability,
	\item the tagged category or categories (Make up the recaptures),
	\item the categories scanned (All the fish sampled for tags),
	\item the length bins if the observations are length-based in an age-based model,
	\item The selectivities for the categories. 
\end{itemize}

An example of a tag recapture observation:

{\small{\begin{verbatim}
		# For the following partition
		@categories
		format sex.area.tag
		names  		male.Area1.2011,notag female.Area1.2011,notag
		
		# individuals tagged in 2011 and recaptured in 2012 in Area1
		@observation Tag_2011_Area1_recap_2012
		type tag_recapture_by_length
		# scanned categories in Area1
		categories format=*.Area1.*+
		# male and femaled tagged categories
		tagged_categories *.Area1.2011+
		detection 0.85 ## detection probability
		likelihood binomial
		selectivities One
		tagged_selectivities One
		# years to apply observation
		years 2012
		time_step step2
		# proportion of mortality applied before observation is calculated
		time_step_proportion 0.5
		
		table scanned
		2012 281271 41360 30239 12234
		end_table
		
		table recaptured
		2012 15 20 12 2
		end_table
		
		# robustification value to prevent divide by zero errors
		delta 1e-11
		# Likelihood dispersion
		dispersion 6.3
		\end{verbatim}}}

The observed ($O_{y,l}$) and expected ($E_{y,l}$) values in year $y$ and length $l$ of this observation are:

\begin{equation}
O_{y,l} = \frac{R_{y,l}}{S_{y,l}}
\end{equation}

where $R_{y,l}$ is the number of recaptures in year $y$ at length $l$ and $S_{y,l}$ are the scanned values.

\begin{equation}
E_{y,l} = d \frac{\tilde{N}_{y,l,t} +  (\tilde{N}_{y,l,t + 1} - \tilde{N}_{y,l,t}) \times p}
{N_{y,l,t} + (N_{y,l,t+1} - N_{y,l,t}) \times p}
\end{equation}

where $\tilde{N}_{y,l,t}$ is an element in the tagged categories at the beginning of time step $t$ and $\tilde{N}_{y,l,t + 1}$ is an element in the tagged categories at the end of time step $t$, $N_{y,l,t}$ is the sum of the categories that were vulnerable to sampling when the observation occurred, $p$ is the proportion of the time step that the observation was taken, and $d$ is the detection probability.

For observations with multiple tagged categories and multiple categories that were vulnerable to sampling:

\begin{equation}
\tilde{N}_{y,l,t} = \sum_{j = 1}^{J} N_{y,l,t,j}
\end{equation}

where $j = \{1,2,3,...,J\}$  are all the tagged categories, the same method is applied to the vulnerable categories to calculate $N_{y,l,t}$. The tagged categories should be defined in the vulnerable categories. In an extreme case where every individual in the population is tagged, this result would be divided by zero. So, to constrain the expectation to be between 0 and 1, the numerator must be in the denominator.

The tag-recapture likelihood (binomial) is specified below. It is a modified version of the more general binomial. Note that this likelihood does not have any user-set precision parameters such as $N$ or $c.v.$, although there are user-specified robustification and dispersion parameters available. The factorials are calculated using the log-gamma function, to allow for non-integer arguments where necessary (and to avoid overflow errors).

\else
% Two column version

\paragraph*{\I{Proportions-at-Length}}\label{sec:Observation-ProportionsAtLength}

Proportions-at-length observations are observations of the relative number of individuals by length, via some selectivity.

The observation is supplied for a given year and time-step, for some selected length bins of the population (i.e., for a range of lengths multiplied by a selectivity). Note that the categories defined in the observations must have an associated selectivity, defined by \subcommand{selectivities}.

The length bins supplied must be a subset of the length bins defined in the \commandsub{model} block. 

Proportions-at-length observations can be supplied as

\begin{itemize}
	\item a set of proportions for a single category,
	\item a set of proportions for multiple categories, or
	\item a set of proportions across aggregated categories.
\end{itemize}

The method of evaluating expectations are the same for all three types of proportions. The definitions of these proportions and the expected dimensions of observation and error inputs that \CNAME\ expects for each respective proportion type are described below with examples.

Like all types of observations that are associated with the mortality block, \CNAME\ will evaluate the numbers at length before and after the mortality block for the specified time step of the observation, and applying the user-defined selectivity. \CNAME\ then generates the expectations from the partition part way through the mortality block using the subcommand \texttt{time\_step\_proportion}. This approximation is a linear interpolation of the numbers-at-age over the mortality block.

Defining an observation for a single category is used to model a set of proportions of a single category by length class. For example, to specify that the observations are of the proportions of male within each length class, then the subcommand \subcommand{categories} for the \commandlabsubarg{observation}{type}{proportion\_by\_length} command is

{\small{\begin{verbatim}
		categories male
		\end{verbatim}}}

\CNAME\ then requires that there will be a single vector of proportions supplied, with one proportion for each length class within the defined length range.


{\small{\begin{verbatim}
		@model
		length_bins 6 8 10 12 14 16 18 20 22 24 26
		@observation MyProportions
		type proportions_at_length
		...
		categories male
		length_bins 10 12 14 16 18 20
		years 1990
		table obs
		1990 0.01 0.09 0.20 0.20 0.35 
		end_table
		...
		\end{verbatim}}}

Defining an observation for multiple categories extends the single category observation definition. It is used to model a set of proportions over several categories by length class. For example, to specify that the observations are of the proportions of male or females within each length class, then the subcommand \subcommand{categories} for the \commandlabsubarg{observation}{type}{proportion\_by\_length} command is

{\small{\begin{verbatim}
		categories male female
		\end{verbatim}}}

\CNAME\ then requires that there will be a single vector of proportions supplied, with one proportion for each category and length class combination, and that these proportions sum to one across all lengths and categories.

For example,

{\small{\begin{verbatim}
		@observation MyProportions
		type proportions_at_length
		...
		categories male female
		length_bins 2 4 6 8 10
		years 1990 1991
		table obs
		1990 0.01 0.05 0.10 0.20 0.20 0.01 0.05 0.15 0.20 0.03
		1991 0.02 0.06 0.10 0.21 0.18 0.02 0.03 0.17 0.20 0.01
		end_table
		...
		\end{verbatim}}}

Defining an observation across aggregated categories allows categories to be aggregated before the proportions are calculated. It is used to model a set of proportions from several categories that have been combined by length class. To indicate that two (or more) categories are to be aggregated, separate them with a '+' symbol. For example, to specify that the observations are of the proportions of male and females combined within each length class, then the subcommand \subcommand{categories} for the \commandlabsubarg{observation}{type}{proportion\_by\_length} command is

{\small{\begin{verbatim}
		categories male + female
		\end{verbatim}}}

\CNAME\ then requires that there will be a single vector of proportions supplied, with one proportion for each length class, and that these proportions sum to one.

For example,

{\small{\begin{verbatim}
		@observation MyProportions
		type proportions_at_length
		...
		years 1990 1991
		categories male+female
		length_bins 2 4 6 8 10
		table obs
		1990 0.02 0.13 0.25 0.30 0.30
		1991 0.02 0.06 0.18 0.35 0.39
		end_table
		...
		\end{verbatim}}}

The latter form can then be extended to include multiple categories, or multiple aggregated categories. For example, to describe proportions for the three groups: immature males, mature males, and all females (immature and mature females added together) for lengths 2 through 8, a total of 8 proportions are required for each year

{\small{\begin{verbatim}
		@observation MyProportions
		type proportions_at_length
		...
		categories male_immature+male_mature female_immature+female_mature
		length_bins 2 4 6 8
		years 1990
		table obs
		year 1990 0.05 0.15 0.15 0.05 0.02 0.03 0.08 0.04 0.05 0.15 0.15 0.08
		end_table
		...
		\end{verbatim}}}

\paragraph*{\I{Proportions-category-by-length observations}}\label{sec:Observation-ProportionsMatureByLength}
Proportions-category observations are observations of relative number of individuals between categories within a range of length classes.

The observation is supplied for a given year and time-step, for selected length classes of the population.


Proportions-by-category observations can be supplied for any set of categories as a proportion of themselves and any set of additional categories. For example, for a model with two categories \emph{male} and \emph{female}, observations of the proportions of males in the population at each length class might be provided. The subcommand \subcommand{categories} defines the categories for the numerator in the calculation of the proportion, and the subcommand \subcommand{total\_categories} supplies the categories to be used in the denominator of the calculation of which the the values of \subcommand{categories} must be included. In addition, each category must have an associated selectivity, defined by \subcommand{selectivities} for the numerator categories and \subcommand{total\_selectivities} for the additional categories used in the denominator.

For example,

{\small{\begin{verbatim}
		categories male
		total_categories male
		selectivities maturity-selectivity
		total_selectivities [type=constant; c=1] ## total population
		\end{verbatim}}}
defines the proportion of mature males in each length class as a proportion of all males. Another example may be males to females
{\small{\begin{verbatim}
		categories male
		total_categories male+female
		selectivities [type=constant; c=1]
		total_selectivities [type=constant; c=1] ## total population
		\end{verbatim}}}
\CNAME\ then requires that there will be a vector of proportions supplied, with one proportion for each length class within the defined length bin range. The expected values will be the expected proportion of \subcommand{categories} to \subcommand{total\_categories}, after applying the selectivities at the year and time-step specified.

For example,

{\small{\begin{verbatim}
		@observation mature_males
		type proportions_by_category
		years 1990 1991
		categories male
		total_categories male
		selectivities maturity-selectivity
		total_selectivities [type=constant; c=1] ## total population
		length_bins 2 4 6 8 10 
		likelihood binomial
		table obs
		1990 0.01 0.05 0.6 1.00 0.820
		1991 0.02 0.06 0.70 0.91 0.988
		end_table
		...
		\end{verbatim}}}

\paragraph*{\I{Tag Recapture by length for growth}\label{sec:Observation-TagRecaptureByLengthForGrowth}}
Designed for situations where you intend to estimate growth using the size frequency of recaptured fish, without using any information on scanned fish. This replicates CASALs tag recapture observation \texttt{type=growth}. 
 
An example of a tag recapture observation:

{\small{\begin{verbatim}
		# For the following partition
		@categories
		format sex.tag
		names  male.2011,notag female.2011,notag
		

@observation 1997_recaptures3_1
type tag_recapture_by_length_for_growth
years 1997
categories male.2011 + female.2011
selectivities One
likelihood multinomial
delta 1e-11
time_step May-Sep
time_step_proportion 0.5
table recaptured
1997 1 2 2 3 2 3 2 3 4
end_table
\end{verbatim}}}

The observed ($O_{y,l}$) and expected ($E_{y,l}$) values in year $y$ and length $l$ of this observation are:

\begin{equation}
O_{y,l} = R_{y,l} \frac{R_{y,l}}{\sum_l R_{y,l}}
\end{equation}

where $R_{y,l}$ is the number of recaptures in year $y$ at length $l$.

The expected value derived from \CNAME\ uses interpolation over the mortality block. The categories defined in the configuration files are calculated over this block as follows.
\begin{equation}
N_{y,l,c} = N^{pre}_{y,l,c} +   (N^{post}_{y,l,c} - N^{pre}_{y,l,c})p
\end{equation}
where, $p$ is the proportion of the time step that the observation was taken, \(N^{pre}_{y,l,c}\) is the partition before the mortality block and \(N^{post}_{y,l,c}\) is the partition after the mortality block.

\begin{equation}
E_{y,l,c} = \frac{N_{y,l,c}}{\sum_c\sum_l N_{y,l,c}}
\end{equation}
where $N_{y,l,c}$ is the number of tagged fish in category \(c\) for year \(y\) and length bin \(l\).

Note that if you are also applying fishing or natural mortality to the population between the time of release and recapture, then the number of fish at size may be biased (although this may depend on the various mortality or fishing selectivities applied). A work-around is to define the tagged fish as being from a separate stock in a separate area (i.e., where they are not subject to fishing mortality, and the natural mortality is either zero or applied as a constant rate over all length classes).
\fi % end if


\subsubsection{\I{General process observations}}

A list of \texttt{types} that are associated with this set of observations:

\begin{itemize}
	\item \texttt{process\_abundance}
	\item \texttt{process\_biomass}
	\item \texttt{process\_proportions\_at\_age}
	\item \texttt{process\_proportions\_at\_length}
	\item \texttt{process\_proportions\_by\_category}
\end{itemize}

These observations have the same expected values as the mortality block versions described in Section \ref{sec:MortalityBlockObservations}. With the exception that instead of wrapping a mortality block they can wrap any process type available in \CNAME.

\subsubsection{\I{Specific process observations}}

A list of \texttt{types} that are associated with this set of observations are:

\ifAgeBased
% One column version
\begin{itemize}
	\item \texttt{process\_removals\_by\_age}
	\item \texttt{process\_removals\_by\_age\_retained}
	\item \texttt{process\_removals\_by\_age\_retained\_total}
	\item \texttt{process\_removals\_by\_length}
	\item \texttt{process\_removals\_by\_length\_retained}
	\item \texttt{process\_removals\_by\_length\_retained\_total}
	\item \texttt{process\_proportions\_migrating}
	
	\paragraph*{\I{Process removals by age}\label{sec:removals-by-age}}\label{sec:Observation-ProcessRemovalsByAge}
	
	Removals-at-age observations are observations of the relative number of individuals at age, part way through a process of type \subcommand{mortality\_instantaneous} or \subcommand{mortality\_hybrid}. This observation can be  associated with the process of type \texttt{mortality\_instantaneous} and \subcommand{mortality\_hybrid}, and will produce an error if any other mortality process type is given.
	
	The observation is supplied for a set of years and specific time-step, for selected age classes of the population (i.e., for a range of ages multiplied by a selectivity that is derived from the process).
	
	The age range must be ages defined in the partition (i.e., between \commandsub{model}{min\_age} and \commandsub{model}{max\_age} inclusive); the upper end of the age range can optionally be a plus group, which must be either the same or less than the plus group defined for the partition.
	
	The expectations from this observation when the process is of type \subcommand{mortality\_instantaneous} are generated whilst the process is being executed. The expectation of numbers at age $a$ for category $c$ from exploitation method $m$ ($E[N_{a,c,m}]$) is
	
	\begin{equation}
	E[N_{a,c,m}] = N_{a,c} U_{a,m} S_{a,c,m} 0.5 M_{a,c}
	\end{equation}
	
	where $N_{a,c}$ are the numbers-at-age in category $c$ before the process is executed, $U_{a,m}$ is the exploitation rate for age $a$ from method $m$, $S_{a,c,m}$ is the selectivity, and $M$ is the natural mortality.
		
	The expectations from this observation when the process is of type \subcommand{mortality\_hybrid} are generated whilst the process is being executed. The expectation of numbers at age $a$ for category $c$ from exploitation method $m$ ($E[N_{a,c,m}]$) is
	
	\begin{equation}
	E[N_{a,c,m}] = \frac{F_{a,m}}{Z_{a,c}} N_{a,c}  S_{a,c,m}
	\end{equation}
	
	where $N_{a,c}$ are the numbers-at-age in category $c$ before the process is executed, $F_{a,m}$ is the fishing mortality rate for age $a$ from method $m$, $S_{a,c,m}$ is the selectivity and $Z_{a,c}$ is the total mortality.
	
	
	
	The observation class accesses the variable $E[N_{a,c,m}]$ and applies ageing error if the user has specified it. Then the observations are aggregated by method and category depending on how the user specifies the observation, before converting numbers-at-age to proportions-at-age and then calculating the likelihood.
	
	Likelihoods that are available for this observation class are the multinomial, Dirichlet, and the lognormal. See Section~\ref{sec:Likelihood} for information on the respected likelihood.
	
	\paragraph*{\I{Process removals by age retained}} \label{sec:Observation-ProcessRemovalsByAgeRetained} \label{sec:Observation-ProcessRemovalsByAgeRetainedTotal}
	
	Observations of retained and total catches by age can be included, using the labels \subcommand{process\_removals\_by\_age\_retained} and \subcommand{process\_removals\_by\_age\_retained\_total}, respectively. Examples of two such observations are given below, with the associated process \subcommand{Instantaneous\_Mortality\_Retained} having the form of the example in Section \ref{sec:Process-MortalityInstantaneousRetained}.
	
	For retained catch:
	
	{\small{\begin{verbatim}
			@observation potFishAFtotal
			type process_removals_by_age_retained_total
			mortality_process Instantaneous_Mortality_Retained
			method_of_removal FishingPot
			years 2005
			time_step 1
			categories male
			### ageing_error Normal_ageing
			min_age 3
			max_age 15
			plus_group True
			table obs
			2005 0.00 0.01 0.16 0.27 0.22 0.16 0.11 0.05 0 0 0 0 0
			end_table
			table error_values
			2005 651
			end_table
			likelihood multinomial
			delta 1e-11
			\end{verbatim}}}
	
	For total catch:
	
	{\small{\begin{verbatim}
			@observation potFishAFretained
			type process_removals_by_age_retained
			mortality_process Instantaneous_Mortality_Retained
			method_of_removal FishingPot
			years 2005
			time_step 1
			categories male
			# ageing_error Normal_ageing
			min_age 3
			max_age 15
			plus_group True
			table obs
			2005 1.65e-10 7.56e-07 1.77e-03 1.96e-01 3.19e-01 2.43e-01 1.60e-01 8.04e-02 0 0 0 0 0
			end_table
			table error_values
			2005 651
			end_table
			likelihood multinomial
			delta 1e-11
			\end{verbatim}}}
	
	\paragraph*{\I{Process removals by length}\label{sec:removals-by-length}}\label{sec:Observation-ProcessRemovalsByLength}
	
	Removals by length observations are observations of the relative number of individuals at length, part way through a process of type \subcommand{mortality\_instantaneous}. This observation is exclusively associated with the process of type \subcommand{mortality\_instantaneous}, and will produce an error if associated with any other process type.
	
	The observation is supplied for a given year and time-step, for some selected age classes of the population (i.e., for a range of ages multiplied by a selectivity that is associated with the process).
	
	The expectations from this observation are generated whilst the process is being executed. The expectation of numbers at age $a$ for category $c$ from exploitation method $m$ ($E[N_{a,c,m}]$) are
	
	\begin{equation}
	E[N_{a,c,m}] = N_{a,c} U_{a,m} S_{a,c,m} 0.5 M_{a,c}
	\end{equation}
	
	where $N_{a,c}$ are the numbers at age in category $c$ before the process is executed, $U_{a,m}$ is the exploitation rate for age $a$ from method $m$, $S_{a,c,m}$ is the selectivity, and $M$ is the natural mortality.
	
	The observation class accesses the variable $E[N_{a,c,m}]$ from the process and applies the age-length relationship specified in the model. This converts numbers-at-age to numbers-at-age and -length, which are then converted to numbers-at-length. The observations are aggregated by method and category depending on how the user specifies the observation, before converting numbers-at-age to proportions and calculating the likelihood.
	
	Similar to the proportions-at-length observation type, the user must supply a vector of length bins. The observation-specific length bins must be a sequential subset of the model length bins, with no missing or added values. For example, if the model length bins are \texttt{0 5 10 15 20 25 ... 100}, then the observation-specific length bins can be \subcommand{20 25 30 35 40 45 50} but not \subcommand{20 30 40 50}.
	
	{\small{\begin{verbatim}
			@observation observation_fishery_LF
			type process_removals_by_length
			...
			years  1993 1994 1995
			method_of_removal FishingEast
			mortality_process instant_mort
			length_plus false
			length_bins 0 20 40 60 80 110
			delta 1e-5
			table obs
			1993    0.0   0.05    0.05    0.10    0.80
			1994    0.05  0.1     0.05    0.05    0.75
			1995    0.3   0.4     0.2     0.05    0.05
			end_table
			
			table error_values
			1993 31
			1994 34
			1995 22
			end_table
			\end{verbatim}}}
	
	Likelihoods that are available for this observation are the multinomial, Dirichlet and the lognormal. See below for information on the likelihoods.
	
	\paragraph*{\I{Process removals by length retained}}\label{sec:Observation-ProcessRemovalsByLengthRetained}\label{sec:Observation-ProcessRemovalsByLengthRetainedTotal}
	
	Observations of retained and total catches by length can be included, using the labels \texttt{process\_removals\_by\_length\_retained} and \texttt{process\_removals\_by\_length\_retained\_total} respectively. Examples of two such observations are given below, with the associated process \texttt{Instantaneous\_Mortality\_Retained} having the form of the example in Section \ref{sec:Process-MortalityInstantaneousRetained}.
	
	Similar to the proportions-at-length observation type, the user must supply a vector of length bins. The observation-specific length bins must be a sequential subset of the model length bins, with no missing or added values. For example, if the model length bins are \subcommand{0 5 10 15 20 25 ... 100}, then the observation-specific length bins can be \subcommand{20 25 30 35 40 45 50} but not \subcommand{20 30 40 50}.
	
	For retained catch:
	
	{\small{\begin{verbatim}
			@observation potFishLFtotal   #test syntax get catch LF out
			type process_removals_by_length_retained_total
			mortality_process Instantaneous_Mortality_Retained
			method_of_removal FishingPot
			years 2005
			time_step 1
			categories male
			length_bins 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # for LF in catch
			length_plus False
			table obs
			2005 0.05 0.06 0.07 0.08 0.08 0.08 0.08 0.08 0.07 0.06 0.06 0.05 0.04 0.030 0.02 0.02
			end_table
			table error_values
			2005 651
			end_table
			likelihood multinomial
			delta 1e-11
			\end{verbatim}}}
	
	For total catch:
	
	{\small{\begin{verbatim}
			@observation potFishLFretained   #test syntax get retained LF out
			type process_removals_by_length_retained
			mortality_process Instantaneous_Mortality_Retained
			method_of_removal FishingPot
			years 2005
			time_step 1
			categories male
			length_bins 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # for LF in catch
			length_plus False
			table obs
			2005 0.02 0.03 0.04 0.06 0.07 0.08 0.08 0.09 0.08 0.08 0.07 0.06 0.05 0.04 0.03 0.02
			end_table
			table error_values
			2005 651
			end_table
			likelihood multinomial
			delta 1e-11
			\end{verbatim}}}
	
	
	\paragraph*{\I{Proportions migrating}\label{sec:Proportions-migrating}}\label{sec:Observation-ProportionsMigrating}
	
	This observation is of the proportion migrating from one area to another. This observation is exclusively associated with the process type \subcommand{transition\_category}, and will produce an error when associated with any other process type. This observation is used to inform migration rates in migration processes. This observation class is used in the hoki stock assessment see~\cite{francis_03} for more information on how these observations are collected and a situation that uses it.
	
	This observation calculates an expectation $E_a$ of proportions for each age class $a$ that have migrated, by
	
	\begin{equation}
	E_a = \frac{N_a - N_a'}{N_a}
	\end{equation}
	
	where $N_a$ are the numbers of individuals in age $a$ before the migration process occurs, and $N_a'$ are the number of individuals after the migration process occurs.
	
	The likelihoods that are allowed for this observation are the lognormal, multinomial, and Dirichlet.
	
	A section of the hoki stock assessment model:
	
	{\small{\begin{verbatim}
			@observation pspawn_1993
			type process_proportions_migrating
			years 1993
			time_step step4
			process Wspmg ## migration process that the observation is associated with
			age_plus true
			min_age 4
			max_age 9
			likelihood lognormal
			categories male.west+female.west ## Categories to evaluate the prportion for
			ageing_error Normal_offset ## label for an @ageing_error block
			table obs
			#age    4    5    6    7    8    9
			1993 0.64 0.58 0.65 0.66 0.71 0.60
			end_table
			
			table error_values
			## if lognormal these are c.v.'s
			1993 0.25
			end_table
			\end{verbatim}}}
	
\end{itemize}


\paragraph*{\I{Tag Recapture by fishery}\label{sec:Observation-TagRecaptureByFishery}}

Tag recaptures can be linked to a specific fishery in a given year and time-step using the \subcommand{tag\_recapture\_by\_fishery} observation. This observation assumes expected tag recaptures are derived from a fishery and are aggregated over all ages and tagged categories for year and time-step. The observation can account for tag reporting rates or detection rates which can be estimated.

Currently \CNAME\ can only apply this observation to mortality processes of type \subcommand{mortality\_hybrid} and \subcommand{mortality\_instantaneous}. The tagged categories labelled in this observation must be also defined in the mortality process, otherwise \CNAME\ will return an error. Ignoring, tag reporting, \CNAME\ will calculate the expected tag recaptures by age and category in the same way as in \subcommand{process\_removals\_by\_age} (see Section~\ref{sec:Observation-ProcessRemovalsByAge}).


Let \(N^f_{a,c,t, y}\) denote the numbers at age for tagged category \(c\) caught by fishery \(f\) in year \(y\) and time-step \(t\). This observation will aggregate over all categories and ages to produce expected values as
\[
E[N^f_{t, y}] = \sum\limits_a\sum\limits_c N^f_{a,c,t, y}
\]

You must specify aggregated observed recaptures for a given year, fishery, time-step and group of tagged categories as shown in the following example (see also Section~\ref{syntax:Observation-TagRecaptureByFishery} for more information on syntax for this observation)
{\small{\begin{verbatim}
			@observation tag_recapture_by_fishing
			years 2000 2001
			type tag_recapture_by_fishery
			tagged_categories R1 R2 R3 R4 
			likelihood poisson
			time_step step1
			mortality_process fishing
			method_of_removal Fishing
			reporting_rate 0.8
			table recaptured
			2000 10120
			2001 8000
			end_table
\end{verbatim}}}

There is currently only one likelihood available for this observation and that is the Poisson ().

\else
\begin{itemize}
	\item \texttt{process\_removals\_by\_length}
	
	\paragraph*{\I{Process removals by length}\label{sec:removals-by-length}}\label{sec:Observation-ProcessRemovalsByLength}
	
	Process-Removals-at-length observations are observations of the relative length frequency part way through a process of type \subcommand{mortality\_instantaneous}. This observation is exclusively associated with the process of type \subcommand{mortality\_instantaneous}, and will produce an error if it is associated with any other process type.
	
	The observation is supplied for a given year and time-step, for selected length classes of exploited categories.

	The expectations from this observation are generated whilst the process is being executed. The expectation of numbers at length $l$ for category $c$ from exploitation method $m$ ($E[N_{l,c,m}]$) are
	
	\begin{equation}
	E[N_{l,c,m}] = N_{l,c} U_{l,m} S_{l,c,m} 0.5 M_{l,c}
	\end{equation}
	
	where $N_{l,c}$ are the numbers-at-age in category $c$ before the process is executed, $U_{l,m}$ is the exploitation rate for length bin $l$ from method $m$, $S_{l,c,m}$ is the selectivity, and $M$ is the natural mortality.
	
	The observation class accesses $E[N_{l,c,m}]$ from the process then the observations are aggregated by method and category depending on how the user specifies the observation, before converting numbers-at-length to proportions-at-length and then calculating the likelihood.
	
	Likelihoods that are available for this observation class are the multinomial, Dirichlet, and the lognormal. See Section~\ref{sec:Likelihood} for information on the respected likelihood.
\end{itemize}
\fi % end if

\subsection{\I{Likelihoods}\index{sec:Likelihoods}}\label{sec:Likelihood}

\subsubsection{Likelihoods for composition observations}

\CNAME\ has a range of likelihoods for composition observations, these include the multinomial, Dirichlet, Dirichlet-Multinomial, and the lognormal likelihood. Composition observations consist of proportions at age or length. The following notation uses \(b\) to denote a composition bin which can be interpreted as an age or length bin.

\subsubsection*{The multinomial likelihood\index{Multinomial likelihood}}

For the observed proportions at age $O_b$ for composition bin $b$ (age or length), with sample size $N$, and the expected proportions for the same bin denoted by $E_b$, the negative log-likelihood is:

\begin{equation}
-\log \left(L \right) =  -\log \left(N! \right) + \sum\limits_b\log \left( \left(NO_b \right)! \right) - NO_b \log \left(Z \left(E_b,\delta \right) \right)
\end{equation}

where $\sum\limits_b O_b = 1$ and $\sum\limits_b E_b = 1$. $Z \left(\theta,\delta \right)$ is a robustifying function to prevent division by zero errors, with parameter $\delta>0$.

\begin{equation}
Z \left(\theta,\delta \right) = \begin{cases}
\theta, & \text{where $\theta \ge r$} \\
\delta/\left( 2-\theta/\delta \right), & \text{otherwise} \\
\end{cases}
\end{equation}

The default value of $\delta$ is $1 \times 10^{-11}$.

\subsubsection*{The Dirichlet likelihood\index{Dirichlet likelihood}}

For the observed proportions at age $O_b$ for composition bin $b$ (age or length), with sample size $N$, and the expected proportions for the same bin denoted by $E_b$, the negative log-likelihood is:

\begin{equation}
-\log \left(L \right) = -\log(\Gamma \sum\limits_b (\alpha_b)) + \sum\limits_b \log(\Gamma (\alpha_b)) - \sum\limits_b (\alpha_b-1) \log(Z(O_b,\delta))
\end{equation}

where $\alpha_b = Z \left(N E_b,\delta \right)$, $\sum\limits_b O_b = 1$, and $\sum\limits_b E_b = 1$. $Z \left(\theta,\delta \right)$ is a robustifying function to prevent division by zero errors, with parameter $\delta>0$.

\begin{equation}
Z \left(\theta,\delta \right) = \begin{cases}
\theta, & \text{where $\theta \ge r$} \\
\delta/\left( 2-\theta/\delta \right), & \text{otherwise} \\
\end{cases}
\end{equation}

The default value of $\delta$ is $1 \times 10^{-11}$.

\subsubsection*{The Dirichlet multinomial likelihood\index{Dirichlet multinomial likelihood}}

The Dirichlet multinomial can be applied using the linear re-parametrised approach from \citep{thorson2017model}. For the observed proportions $O_b$ for composition bin $b$ (age or length), with sample size $N$, expected proportions for the same bin denoted by $E_b$, and estimable overdispersion parameter \(\theta\), the negative log-likelihood is:

\begin{align*}
-\log \left(L \right) &=  -\log \Gamma \left(N + 1 \right) + \sum\limits_b \log \left( \Gamma \left(NO_b + 1\right) \right) + \\
 & \ \ \ \log \Gamma \left(\theta N\right) + \log \Gamma \left(N + \theta N\right)  NO_b - \sum\limits_b \log (NO_b + \theta N E_b) - \log(\theta N E_b)
\end{align*}

which has an effective sample size \(n_{eff}\)

\[
n_{eff} = \frac{1 + \theta N}{1 + \theta} = \frac{1}{1 + \theta} + N\frac{\theta}{1 + \theta}
\]

where the effective sample size is a linear function of input sample size with intercept \((1 + \theta)^{-1}\)  and slope \(\frac{\theta}{1 + \theta}\). \CNAME\ will report the \(n_{eff}\) in the observation report under the column label \subcommand{adjusted\_error}.

Interpreting \(\theta\):

\begin{itemize}
	\item if \(\theta\) is large then \(n_{eff} \rightarrow N\)
	\item if \(\theta \ll N \) and \(N > 1\) then \(\theta\) can be interpreted as the ratio of the effective sample size over the input sample size.
\end{itemize}

If you estimate \(\theta\) it is recommended to apply a transformation such as log (see below for example syntax), \CNAME\ will error out if there is not transformation applied to \(\theta\). This likelihood is quite different to configure compared with other likelihood types because it has an estimable parameter you need to define a \command{likelihood} block and it cannot have a \subcommand{label} that is the same as a \subcommand{type} from any of the other likelihoods.

{\small{\begin{verbatim}
@likelihood DirichletMultinomialFisheryAge
type dirichlet_multinomial
theta 1

@observation FisheryAge
type proportions_at_age
...
likelihood DirichletMultinomialFisheryAge

@parameter_transformation log_theta
type log
parameter likelihood[DirichletMultinomialFisheryAge].theta
\end{verbatim}}}


\subsubsection*{The lognormal likelihood\index{Lognormal likelihood}}

For the observed proportions at age $O_b$ for bin $b$, with c.v. $c_b$, and the expected proportions at the same age classes $E_b$, the negative log-likelihood is defined as;

\begin{equation}
- \log \left(L \right) = \sum\limits_b \left( \log \left( \sigma_b \right) + 0.5\left( \frac{\log \left(O_b / Z \left(E_b,\delta \right) \right)}{\sigma_b} + 0.5 \sigma_b \right)^2 \right)
\end{equation}

where

\begin{equation}
\sigma_b  = \sqrt{\log \left(1+c_b^2 \right)}
\end{equation}

and the $c_b$'s are the c.v.s for each composition bin $b$, and $Z \left(\theta,\delta \right)$ is a robustifying function to prevent division by zero errors, with parameter $\delta>0$.

\begin{equation}
Z \left(\theta,\delta \right) = \begin{cases}
\theta, & \text{where $\theta \ge r$} \\
\delta/\left( 2-\theta/\delta \right), & \text{otherwise} \\
\end{cases}
\end{equation}

The default value of $\delta$ is $1 \times 10^{-11}$.


\subsubsection{Likelihoods for abundance and biomass observations}\label{Obs:biomass}

Abundance and biomass observations are expected as an annual time series in \CNAME, where they select the same categories over that time series. The parameters and inputs needed to use this observation class are: a observation $O_i$, c.v. $c_i$, catchability coefficient $q$, where $i$ indexed the year. \CNAME\ calculates an expectation $E_i$ and scales it by $q$ before comparing it to $O_i$. This means that the value chosen for $q$ will determine whether the observation is relative ($q\neq 1$) or absolute $q = 1$. Before we describe each of the likelihoods we will discuss the methods available to handle $q$s:

\begin{itemize}
	\item The $q$s can be treated as 'nuisance' parameters. For each set of values of the free parameters, the model uses the values of the $q$s which minimise the objective function. These optimal $q$s are calculated algebraically (see Section~\ref{subsec:nuisance}). If one of the $q$s falls outside the bounds specified by the user, it is set equal to the closest bound. This approach reduces the size of the parameter vector and hence should improve the performance of the estimation method. However, it is not correct when calculating a sample from the posterior in a Bayesian analysis (except asymptotically, see \cite{Walters_ludwig_94}) and we offer the following alternative;

	\item The $q$s can be treated as ordinary free parameters.
\end{itemize}

For both options, it is necessary to evaluate the contribution of $O_i$ to the negative log likelihood for a given value of $q$. Each observation $O_i$ varies about $qE_i$, which expresses the variability of $O_i$ in terms of its c.v. $c_i$ (or in one case, its standard deviation si). Here are the likelihoods, which are expressed on the objective-function scale of -log(L):

\subsubsection*{The lognormal likelihood\index{Lognormal likelihood}\index{Lognormal likelihood}}

The negative log likelihood for the lognormal is

\begin{equation}
- \log \left(L \right) = \sum\limits_i \left( \log \left( \sigma _i \right) + 0.5\left( \frac{\log \left(O_i / q Z \left(E_i,\delta \right) \right)}{\sigma_i} + 0.5 \sigma_i \right)^2 \right)
\end{equation}

where

\begin{equation}
\sigma_i  = \sqrt{\log \left(1+c_i^2 \right)}
\end{equation}

and $Z \left(\theta,\delta \right)$ is a robustifying function to prevent division by zero errors, with parameter $\delta>0$.

\begin{equation}
Z \left(\theta,\delta \right) = \begin{cases}
\theta, & \text{where $\theta \ge r$} \\
\delta/\left( 2-\theta/\delta \right), & \text{otherwise} \\
\end{cases}
\end{equation}

The default value of $\delta$ is $1 \times 10^{-11}$.

This formulation reflects the distributional assumptions that  $O_i$ has the lognormal distribution, that the mean of $O_i$ is $qE_i$  and the c.v. of $O_i$ is $c_i$.

\subsubsection*{The normal likelihood\index{Normal likelihood}\index{Normal likelihood}}

For observations $O_i$, c.v. $c_i$, and expected values $qE_i$, the negative log-likelihood is defined as;

\begin{equation}
- \log \left(L \right) = \sum\limits_i \left( \log \left( c_i E_i \right) +0.5 \left( \frac{O_i-E_i}{Z\left(c_i E_i,\delta \right)}\right)^2\right)
\end{equation}

and $Z \left(\theta,\delta \right)$ is a robustifying function to prevent division by zero errors, with parameter $\delta>0$.

\begin{equation}
Z \left(\theta,\delta \right) = \begin{cases}
\theta, & \text{where $\theta \ge r$} \\
\delta/\left( 2-\theta/\delta \right), & \text{otherwise} \\
\end{cases}
\end{equation}

The default value of $\delta$ is $1 \times 10^{-11}$.

This reflects the distributional assumptions that  $O_i$ has the normal distribution, that the mean of $O_i$ is $qE_i$  and the c.v. of $O_i$ is $c_i$.

\subsubsection{Likelihoods for tag recapture by age and length observations}
\paragraph*{The binomial likelihood\index{Binomial likelihood ! tag-recapture-by-length}}

This likelihood is for situations where the length frequencies or age frequencies of both recaptured tagged fish and of the scanned fish are known. Available in both age or length based models.

The likelihood is defined as a binomial, and based on lengths or ages for both the tag recaptures and scanned individuals. 

\begin{equation}
\begin{split}
-\log \left(L \right)'= -\sum\limits_i & \left[ \right. \log \left(n_i! \right) - \log \left(\left(n_i - m_i \right)! \right) - \log \left(\left(m_i \right)! \right) + m_i \log \left(Z\left(\frac{M_i}{N_i},\delta \right) \right) \\
&+  \left(n_i - m_i \right)\log \left(Z\left(1 - \frac{M_i}{N_i},\delta\right) \right) \left. \right]
\end{split}
\end{equation}

where

$n_i$ = number of fish at length or age $i$ that were scanned

$m_i$ = number of fish at length or age $i$ that were recaptured

$N_i$ = number of fish at length or age $i$ in the available population (tagged and untagged)

$M_i$ = number of fish at length or age $i$ in the available population that have the tag after a detection probability $p_d$ has been applied, $M_i = M_i'p_d$, where $M_i'$ is the expected available population that have the tag.

$Z(x,\delta)$ is a robustifying function with parameter $r > 0$ (to prevent division by zero errors).

\[ Z(x,\delta) =
\begin{cases}
x       & \text{where } x \geq \delta\\
\frac{\delta}{(2 - x / \delta)}  & \text{otherwise}\\
\end{cases}
\]

If an over-dispersion parameter ($\tau$) is specified then the final negative log likelihood $-log(L)$ contribution is

$$-log(L) = -log(L)' / \tau$$

Note that the over-dispersion is mathematically equivalent to the inverse of a likelihood multiplier on the final negative log-likelihood value, and hence either can be used to achieve the same effect. 

\subsubsection{Likelihoods for proportions-by-category observations}

\CNAME\ implements two likelihoods for proportions-by-category observations, the binomial likelihood, and the normal approximation to the binomial (binomial-approx).

\subsubsection*{The binomial likelihood\index{Binomial likelihood ! proportions-by-category}}

For observed proportions $O_i$ for age class $i$, where $E_i$ are the expected proportions for age class $i$, and $N_i$ is the effective sample size for age class $i$, then the negative log-likelihood is

\begin{equation}
\begin{split}
-\log \left(L \right)= -\sum\limits_i & \left[ \right. \log \left(N_i! \right) - \log \left(\left(N_i \left(1 - O_i \right) \right)! \right) - \log \left(\left(N_i O_i \right)! \right) + N_i O_i \log \left(Z\left(E_i,\delta \right) \right) \\
&+ N_i \left(1 - O_i \right)\log \left(Z\left(1 - E_i,\delta\right) \right) \left. \right]
\end{split}
\end{equation}

where $Z \left(\theta,\delta \right)$ is a robustifying function to prevent division by zero errors, with parameter $\delta>0$.

\begin{equation}
Z \left(\theta,\delta \right) = \begin{cases}
\theta, & \text{where $\theta \ge r$} \\
\delta/\left( 2-\theta/\delta \right), & \text{otherwise} \\
\end{cases}
\end{equation}

The default value of $\delta$ is $1 \times 10^{-11}$.

\subsubsection*{The normal approximation to the binomial likelihood\index{Binomial likelihood (normal approximation) ! proportions-by-category}}

For observed proportions $O_i$ for age class $i$, where $E_i$ are the expected proportions for age class $i$, and $N_i$ is the effective sample size for age class $i$, then the negative log-likelihood is defined as;

\begin{equation}
-\log \left(L \right)= \sum\limits_i \log \left( \sqrt{Z\left(E_i,\delta \right)Z\left(1-E_i,\delta\right)/N_i} \right) + \frac{1}{2} \left( \frac{O_i-E_i}{\sqrt{Z\left(E_i,\delta\right)Z\left(1-E_i,\delta \right)/N_i}} \right)^2
\end{equation}

where $Z \left(\theta,\delta \right)$ is a robustifying function to prevent division by zero errors, with parameter $\delta>0$.

\begin{equation}
Z \left(\theta,\delta \right) = \begin{cases}
\theta, & \text{where $\theta \ge r$} \\
\delta/\left( 2-\theta/\delta \right), & \text{otherwise} \\
\end{cases}
\end{equation}

The default value of $\delta$ is $1 \times 10^{-11}$.


\subsubsection*{The Poisson likelihood\index{Poisson likelihood}}

For observed value $O_i$ and expected value $E_i$ the negative log-likelihood is defined as;

\begin{equation}
	-\log \left(L \right) = -\left(-Z\left(E_i,\delta \right) + O_i log\left(Z\left(E_i,\delta \right)\right) - log \Gamma \left(O_i+1\right) \right)
\end{equation}

where $Z \left(\theta,\delta \right)$ is a robustifying function to prevent log of zero errors, with parameter $\delta>0$.

\subsection{\I{Process error}}

Additional 'process error' can be defined for any set of observations. Additional process error has the effect of increasing the observation error in the data, and hence of decreasing the relative weight given to the data in the fitting process.

For observations where the likelihood is parameterised by the c.v., the process error can be specified for a given set of observations as a c.v., in which case all the c.v.s $c_i$ are changed to

\begin{equation}
  c'_i  = \sqrt {c_i^2  + c_{process\_error}^2 }
\end{equation}

Note that $c_{process\_ error} \ge 0$, and that $c_{process\_ error} = 0$ is equivalent to no process error.

Similarly, if the likelihood is parameterised by the effective sample size $N$,

\begin{equation}
 N'_i  = \frac{1}{1 / {N_i}+ 1 / N_{process\_error}}
\end{equation}

Note that this requires that $N_{process\_ error} > 0$, but the special case of $N_{process\_ error}=0$ is valid, and $N_{process\_ error}=0$ represents no process error (i.e., defined to be equivalent to $N_{process\_ error}=\infty$).

For both the c.v. and $N$ process errors, the process error has more effect on small errors than on large ones. Note that a large value for the $N$ process error means a small process error.
\subsection{\I{Catchability \emph{q} parameters}}\label{subsec:catchabilities}

Catchability parameters often denoted by \(q\) are used in abundance or biomass observations to scale the model expected value to the observed value (see Section~\ref{sec:Observation-Abundance}). \CNAME\ has two methods for implementing catchability parameters, \subcommand{free} and \subcommand{nuisance}. 

The \subcommand{free} approach treats the catchability parameters like all other parameters, where a prior needs to be assumed and it is estimated in the usual fashion.

The \subcommand{nuisance} approach treats the catchability parameters like all other parameters, where a prior needs to be assumed and it is estimated in the usual fashion.
\subsubsection{\I{Free \emph{q}}}\label{subsec:free}

(see Section~\ref{syntax:Catchability-Free} for additional details on syntax)


{\small{\begin{verbatim}
		@catchability CPUEq
		type free
		q 0.1
\end{verbatim}}}


\subsubsection{\I{Nuisance \emph{q}}}\label{subsec:nuisance}
This section describes the algorithms \CNAME\ uses to derive nuisance (analytical) catchability coefficients $q$s (see Section~\ref{syntax:Catchability-Nuisance} for additional details on syntax). From the user's point of view, the essence is that you can use nuisance $q$s in the following situations:

\begin{itemize}
	\item With maximum likelihood estimation
	\item With Bayesian estimation, providing that the additional prior on $q$ is one of the following:
		\begin{itemize}
			\item None (default)
			\item Uniform-log
			\item Lognormal with observations distributed lognormal, robustified lognormal
		\end{itemize}
\end{itemize}

The scenarios in which the nuisance catchability $q$ can be used in a Bayesian analysis (Table~\ref{tab:nus_overview}):

\begin{table}[h!]
	\caption{\textbf{Equations used to calculate nuisance $q$s. (*=no analytic solution found.)}}\label{tab:nus_overview}
	\begin{tabular}{cccccc}
		Distribution & Maximum Likelihood & None & Uniform-log & Normal & lognormal\\
		\hline
		Normal & \eqref{EQ:1} & \eqref{EQ:1} & \eqref{EQ:3} & \textbf{*} & \textbf{*} \\
		Lognormal & \eqref{EQ:4} & \eqref{EQ:4} & \eqref{EQ:8} & \textbf{*} & \eqref{EQ:9} \\
	\end{tabular}
\end{table}

%% Insert table 4 here

Note that $q$s are calculated for robustified lognormal likelihoods as if they were ordinary lognormal likelihoods.

Let $\sigma_i = \sqrt{log(1 + c_i^2)}$ throughout, and let $n$ be the number of observations in the time series. The case of multiple time series sharing the same $q$, and the modifications required for the assumption of curvature, are addressed at the end of this subsection.

First, consider maximum likelihood estimation. When the ($Oi$) are assumed to be normally distributed

\begin{equation}\label{EQ:1}
-log(L) = \sum_i log (c_iqE_i) + 0.5\sum_i \bigg(\frac{O_i - qE_i}{c_iqE_i} \bigg)^2
\end{equation}

The value of $q$ which minimises the objective function is found by solving for $q$ under the following condition, $\partial/\partial q(-log(L)) = 0$

\begin{equation}\label{EQ:2}
\frac{\partial }{\partial q}(-log(L)) = \frac{n}{q} + \frac{1}{q^2} \sum_i \frac{O_i}{c_i^2E_i} - \frac{1}{q^3} \sum_i \bigg(\frac{O_i}{c_iE_i}\bigg)^2
\end{equation}

hence

\begin{equation}\label{EQ:3}
\hat q = \frac{-S_1 + \sqrt{S_1^2 + 4nS_2}}{2n}
\end{equation}

where $S_1 = \sum_i (O_i/c_i^2E_i)$ and $S_2 = \sum_i (O_i/c_iE_i)^2$

When the ($O_i$) are assumed to be lognormally distributed,

\begin{equation}\label{EQ:4}
-log(L) = \sum_i log (\sigma_i) + 0.5\sum_i \bigg(\frac{log(O_i) - log(qE_i) + 0.5\sigma_i^2}{\sigma_i} \bigg)^2
\end{equation}

\begin{equation}\label{EQ:5}
\frac{\partial }{\partial q}(-log(L)) = \frac{-1}{q} \sum_i\bigg( \frac{log(O_i/E_i) - log(q) + 0.5\sigma_i^2}{\sigma_i^2}\bigg)
\end{equation}

\begin{equation}\label{EQ:6}
\hat q = exp\frac{0.5n + S_3}{S_4}
\end{equation}

where $S_3 = \sum_i (log(O_i /E_I)/\sigma_i^2)$ and $S_4 = \sum_i(1/\sigma_i^2)$.

Next, consider Bayesian estimation, where a prior for $q$ must be specified.

The effects of the prior on the equations are to replace likelihood $L$ by posterior $P$ throughout, to add $-log(\pi(q))$ to the equation for $-log(P)$ and $\partial/\partial q(-log(-\pi(q)))$ to the equation for $\partial/\partial q(-log(P))$

This last term is 0 for a uniform prior on $q$, $1/q$ for a log-uniform prior, and $\frac{1}{q}\bigg( 1.5 + \frac{log(q) - log(\mu_q)}{\sigma_q^2}$ for a lognormal prior, where $\mu_q$ and $c_q$ are the mean and c.v. of the prior on $q$, respectively, and $\sigma_q = \sqrt{log(1+c_q^2)}$. Since the prior is uniform, the equation for $\hat q$ is the same as the maximum likelihood estimation.

When the $(O_i)$ are assumed to be normally distributed and the prior is log-uniform equation~\eqref{EQ:3} becomes,

\begin{equation}\label{EQ:7}
\hat q = \frac{-S_1 + \sqrt{S_1^2 + 4(n + 1)S_2}}{2(n+1)}
\end{equation}

but $\hat q$ with either a Normal or Lognormal prior cannot be solved for.

When the $O_i$ are assumed to be Lognormally distributed and the prior is log-uniform, equation~\eqref{EQ:6} becomes


\begin{equation}\label{EQ:8}
\hat q = exp\frac{0.5n -1 + S_3}{S_4}
\end{equation}

and if the prior is Lognormal,

\begin{equation}\label{EQ:9}
\hat q = exp\frac{0.5n -1.5 + log(\mu_q)/\sigma_q^2 + S_3}{S_4 + 1 / \sigma_q^2}
\end{equation}

However, it is not possible to solve for $\hat q$ with a normal prior.

An example of specifying the syntax and an equivalent additional prior

{\small{\begin{verbatim}
	@catchability chatTANq
	type nuisance
	upper_bound 0.6
	lower_bound 0.0001

	@additional_prior chatTANq_prior
	type lognormal
	parameter catchabilityp[chatTANq].q
	mu 0.3
	cv 0.2
\end{verbatim}}}

\ifAgeBased
\subsection{\I{Ageing error}}\label{sec:AgeingError}

\CNAME\ can apply ageing error to expected age frequencies estimated by the model. The ageing error is applied as a misclassification matrix, which has the effect of 'smearing' the expected age frequencies. This is mimicking the error involved in identifying the age of individuals. For example, fish species are aged by reading the ear bones (otoliths) which can be quite difficult depending on the species. These age frequencies are used in calculating the fits to the observed values, and hence the contribution to the total objective function.

Ageing error is optional, and if it is used, it may be omitted for any individual time series. Different ageing error models may be applied for different observation commands. See Section \ref{syntax:Report-AgeingErrorMatrix} for reporting the misclassification matrix at the end of model run.

The ageing error models implemented are

\begin{itemize}
  \item{None}: The default model is to apply no ageing error.\label{sec:AgeingError-None}
  \item{Off by one}: Proportion $p_1$ of individuals of each age $a$ are misclassified as age $a-1$ and proportion $p_2$ are misclassified as age $a+1$. Individuals of age $a < k$ are not misclassified. If there is no plus group in the population model, then proportion $p_2$ of the oldest age class will 'fall off the edge and disappear'.\label{sec:AgeingError-OffByOne}
  \item{Normal}: Individuals of age $a$ are classified as ages which are normally distributed with mean $a$ and constant c.v. $c$. As above, if there is no plus group in the population model, some individuals of the older age classes may disappear. If $c$ is high enough, some of the younger age classes may 'fall off the other edge'. Individuals of age $a < k$ are not misclassified.\label{sec:AgeingError-Normal}
  \item{Data}: A matrix that defines the misclassification matrix for ageing error\label{sec:AgeingError-Data}.
\end{itemize}

The expected values (fits) reported by \CNAME\ for observations with ageing error will have had the ageing error applied.
\fi

\subsection{\I{Simulating observations}}\label{sec:Simulate}

\CNAME\ can generate simulated observations for a given model with a set of parameter values using \texttt{casal2 -s $n$} to simulate $n$ sets of observations). Simulated observations are randomly generated values, which are generated with the error distributions defined for each observation, around fits calculated from one or more sets of the 'true' parameter values. Simulating from a set of parameters can be used to generate observations from an operating model or as a form of parametric bootstrap. 


%The only type of simulations implemented is the type \texttt{constant} \label{sec:Simulate-Constant}.

The procedure \CNAME\ uses for simulating observations is to use the 'true' parameter values which are fed via the \texttt{-i}/\texttt{-I} file input which generate expected values. Then, if a set of observations use ageing error, ageing error is applied. Finally, a random value for each observed value is generated based on (i) the expected values, (ii) the type of likelihood specified, and (iii) the variability parameters (e.g., \subcommand{error\_value} and \subcommand{process\_error}).

Methods for generating the random error, and hence the simulated values, have three components which the user can change. These are the (i) the likelihood choice and observation error, (ii) parameter uncertainty through the use of \texttt{-i}/\texttt{-I}, and (iii) time-varying parameters. 

\begin{itemize}
  \item{} Normal likelihood parameterised by c.v.: Let $E_{i}$ be the fitted value for observation $i$, and $c_i$ be the corresponding c.v. (adjusted by the process error if applicable). Each simulated observation value $S_i$ is generated as an independent normal deviate with mean $E_i$ and standard deviation $E_i c_i$.
  \item{} Log-normal likelihood: Let $E_i$ be the fitted value for observation $i$ and $c_i$ be the corresponding c.v. (adjusted by the process error if applicable). Each simulated observation value $S_i$ is generated as an independent lognormal deviate with mean and standard deviation (on the natural scale, not the log-scale) of $E_i$ and $E_i c_i$ respectively. The robustification parameter $\delta$ is ignored.
  \item{} Multinomial likelihood: Let $E_i$ be the fitted value for observation $i$, for $i$ between $1$ and $n$, and let $N$ be the sample size (adjusted by process error if applicable, and then rounded up to the next whole number). The robustification parameter $\delta$ is ignored. Then,
  \begin{enumerate}
    \item{} A sample of $N$ values from $1$ to $n$ is generated using the multinomial distribution, using sample probabilities proportional to the values of $E_i$.
    \item{} Each simulated observation value $S_i$ is calculated as the proportion of the $N$ sampled values equalling $i$
    \item{} The simulated observation values $S_i$ are then rescaled so that their sum is equal to $1$
  \end{enumerate}
  \item{} Binomial and the normal approximation to the binomial likelihoods: Let $E_i$ be the fitted value for observation $i$, for $i$ between $1$ and $n$, and $N_i$ the corresponding equivalent sample size (adjusted by process error if applicable, and then rounded up to the next whole number). The robustification parameter $\delta$ is ignored. Then,
  \begin{enumerate}
    \item{} A sample of $N_i$ independent binary variates is generated, equalling $1$ with probability $E_i$
    \item{}	The simulated observation value $S_i$ is calculated as the sum of these binary variates divided by $N_i$
  \end{enumerate}
\end{itemize}

\textbf{An important note when simulating:} \CNAME\ will \textbf{not} automatically report simulated observations when using a \texttt{casal2 -s 1 -i input\_pars.out} run. A report must be defined using the \subcommand{simulated\_observation} report (\commandlabsubarg{report}{type}{observation}). For completeness the report is described along with some best practices here, but there is additional information in Section \ref{sec:Report}.


A typical report for simulating an observation looks like
\begin{verbatim}
@report CPUE_index_sim # report label
type simulated_observation # report tyoe
observation CPUEandes # observation to simulate
file_name sim/CPUEandes # file to write simualted data to
\end{verbatim}
%
\textbf{note} that in the subcommand \subcommand{file\_name} there is a directory component \texttt{sim}. It is recommended when doing simulations that you create directories that can be documented on what configurations caused that set of simulated datasets. This will become useful if you are looking at multiple simulated models assumptions.


Simulated reports will be produced with the following extension \texttt{.1\_1}. The first number of the extension relates to the row of the \texttt{-i}/\texttt{-I} file and the second number (separated by \texttt{\_}) represents the simulation iteration defined by the \texttt{n} argument in the configuration input \texttt{casal2 -s n}. Examples of the extension follow,
\begin{itemize}
	\item \texttt{.1\_1} indicates simulated data produced from the first row of parameters and is the first random draw
	\item \texttt{.1\_2} indicates simulated data produced from the first row of parameters and is the second random draw
	\item \texttt{.2\_10} indicates simulated data produced from the second row of parameters and is the 10\(^{th}\) random draw
\end{itemize}

%Given a model structure, there are three ways users can add introduce uncertainty into simulated datasets, the likelihood structure, parameters inputs, and time-varying parameters (see section~\ref{sec:TimeVarying}).

%The likelihood will automatically add observation error when running \CNAME\ with the command \texttt{casal2 -s 100}. Multiple parameter values and addressable (see section) can be adjusted using the arguments  \texttt{casal2 -s 1 -i pars.out} where there are 100 rows with differing parameter values in the\texttt{pars.out} file.


\subsection{\I{Pseudo-observations}}\label{sec:PseudoObservations}

\CNAME\ can generate expected values for observations without them contributing to the total objective function. These are called pseudo-observations, and can be used to either generate the expected values from \CNAME\ for reporting or diagnostic purposes. To define an observation as a pseudo-observation, use the command \commandlabsubarg{observation}{likelihood}{none}. Any observation type can be used as a pseudo-observation. \CNAME\ can also generate simulated observations from pseudo-observations. Note that

\begin{itemize}
  \item Output will be generated only if a report command \commandlabsubarg{report}{type}{observation} is specified.
  \item The observed values should be supplied (even if they are 'dummy' observations). These observation values will be processed by \CNAME\ as if they were actual observation values, and must be in the same format as actual observation values.
  \item The subcommands \subcommand{likelihood}, \subcommand{obs}, \subcommand{error\_value}, and \subcommand{process\_error} have no effect when generating the expected values for the pseudo-observation.
  \item When simulating observations, the subcommand \subcommand{simulation\_likelihood} to indicate the likelihood to use. In this case, the \subcommand{obs}, \subcommand{error\_value}, and \subcommand{process\_error} are used to determine the appropriate terms to use for the likelihood when simulating.
\end{itemize}


\subsection{\I{Residuals}}\label{sec:Residuals}

\CNAME\ will print the default residual values (i.e., observed less fitted) only when the report type \command{report}\subcommand{.type=observation} is used. For an observation \textit{O} and \textit{F} the corresponding fit (=\textit{qE} for relative observations), then

\begin{itemize}
	\item Residuals = \textit{O} - \textit{F}
\end{itemize}

Pearson and normalised residuals can be generated using the \CNAME\ \textbf{R} package. For specific \R\ functions see Section~\ref{sec:PostProcessing}.

The definitions used in the calculations are

\begin{itemize}
	\item \textit{Pearson residuals} attempt to express the residual relative to the variability of the observation, and are defined as (\textit{O}-\textit{F})/std.dev.(\textit{O}), where std.dev.(\textit{O}) is calculated as
	\begin{itemize}
			\item F $\times$ cv for normal, lognormal, robustified lognormal, and normal-log error distributions.
			\item s for normal-by-standard deviation error distributions.
			\item $\sqrt{\frac{Z(\textit{F},r)(1 - Z(\textit{F},r))}{N}}$ for multinomial or binomial likelihoods.
			\item $\sqrt{\frac{(\textit{F} + r)(1 - \textit{F} + r)}{N}}$ for binomial-approx likelihood likelihoods.
	\end{itemize}
	\item \textit{Normalised residuals} to express the residual on a standard normal scale, and are defined as:
	\begin{itemize}
		\item Equal to the Pearson residuals for normal error distributions.
		\item (log(\textit{O}/\textit{F})+0.5$\sigma^2$)/$\sigma$ for lognormal (including robustified lognormal) error distributions, where $\sigma= \sqrt{log(1 + cv^2)}$.
		\item  log(\textit{O}/\textit{F})/$\sigma$ for normal-log error distributions, again with $\sigma= \sqrt{log(1 + cv^2)}$.
		\item And are otherwise undefined.
	\end{itemize}
\end{itemize}

where $Z(\textit{F},r)$ is the robustifying term on \textit{F} (fit or expectation of the observation). This robustifying function is described earlier in the likelihood section.

